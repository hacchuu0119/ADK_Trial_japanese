{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np0plMPXRvoq"
      },
      "source": [
        " ### 最初のインテリジェントエージェントチームを構築しよう: ADKを使った進化するウェザーボット\n",
        " \n",
        " このチュートリアルは、[Agent Development Kit](https://google.github.io/adk-docs/get-started/)の[クイックスタート例]https://google.github.io/adk-docs/get-started/quickstart/)を拡張したものです。今、あなたはより深く掘り下げ、より洗練された**ルチエージェントシステム**を構築する準備ができています。\n",
        " \n",
        " 私たちは、**ウェザーボットエージェントチーム**を構築し、シンプルな基盤に高度な機能を段階的に追加していきます。天気を調べることがきる単一のエージェントから始め、次のような機能を段階的に追加します:\n",
        " \n",
        " *   異なるAIモデル（Gemini、GPT、Claude）を活用する。\n",
        " *   特定のタスク（挨拶や別れの挨拶など）に特化したサブエージェントを設計する。\n",
        " *   エージェント間のインテリジェントな委任を可能にする。\n",
        " *   永続的なセッション状態を使用してエージェントに記憶を与える。\n",
        " *   コールバックを使用して重要な安全ガードレールを実装する。\n",
        " \n",
        " **なぜウェザーボットチームなのか？**\n",
        " \n",
        " このユースケースは、一見シンプルに見えますが、複雑で現実的なエージェントアプリケーションを構築するために必要なADKのコアコンセプト探求するための実用的で親しみやすいキャンバスを提供します。インタラクションの構造化、状態の管理、安全性の確保、複数のAI「頭脳」を協させる方法を学びます。\n",
        " \n",
        " **ADKとは何か？**\n",
        " \n",
        " ADKは、大規模言語モデル（LLM）を活用したアプリケーションの開発を効率化するために設計されたPythonフレームワークです。エージェント推論し、計画し、ツールを利用し、ユーザーと動的に対話し、チーム内で効果的に協力するための強力な構成要素を提供します。\n",
        " \n",
        " **この高度なチュートリアルで習得すること:**\n",
        " \n",
        " *   ✅ **ツールの定義と使用法:** エージェントに特定の能力（データの取得など）を与えるPython関数（`tools`）を作成し、それを効果的使用する方法をエージェントに指示します。\n",
        " *   ✅ **マルチLLMの柔軟性:** LiteLLM統合を通じて、Gemini、GPT-4o、Claude Sonnetなどのさまざまな主要LLMを利用するようにエージントを設定し、各タスクに最適なモデルを選択できるようにします。\n",
        " *   ✅ **エージェントの委任と協力:** 特化したサブエージェントを設計し、チーム内で最も適切なエージェントにユーザーリクエストを自動にルーティングする（`auto flow`）を可能にします。\n",
        " *   ✅ **メモリのためのセッション状態:** `Session State`と`ToolContext`を利用して、エージェントが会話のターンを超えて情報を記し、よりコンテキストに基づいたインタラクションを実現します。\n",
        " *   ✅ **コールバックによる安全ガードレール:** `before_model_callback`と`before_tool_callback`を実装して、事前定義されたルーに基づいてリクエストやツールの使用を検査、修正、またはブロックし、アプリケーションの安全性と制御を強化します。\n",
        " \n",
        " **最終状態の期待:**\n",
        " \n",
        " このチュートリアルを完了することで、機能的なマルチエージェントウェザーボットシステムを構築することができます。このシステムは、天気情報を提供するだけでなく、会話の礼儀を処理し、最後に確認した都市を記憶し、定義された安全境界内で動作し、すべてADKを使用して調整されます。\n",
        " \n",
        " **前提条件:**\n",
        " \n",
        " *   ✅ **Pythonプログラミングの確かな理解。**\n",
        " *   ✅ **大規模言語モデル（LLM）、API、およびエージェントの概念に精通していること。**\n",
        " *   ❗ **重要: ADKクイックスタートチュートリアルの完了、またはADKの基本（エージェント、ランナー、セッションサービス、基本的なツーの使用法）に関する同等の基礎知識。** このチュートリアルはこれらの概念に直接基づいています。\n",
        " *   ✅ **使用するLLMのAPIキー**（例: Gemini用のGoogle AI Studio、OpenAIプラットフォーム、Anthropicコンソール）。\n",
        " \n",
        " **エージェントチームを構築する準備はできましたか？さあ、始めましょう！**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ARCoeUZCRNGi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installation complete.\n"
          ]
        }
      ],
      "source": [
        "# @title Step 0: Setup and Installation\n",
        "# Install ADK and LiteLLM for multi-model support\n",
        "\n",
        "!pip install google-adk -q\n",
        "!pip install litellm -q\n",
        "\n",
        "print(\"Installation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sbwxKypOSBkN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ],
      "source": [
        "# @title Import necessary libraries\n",
        "import os\n",
        "import asyncio\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.genai import types # For creating message Content/Parts\n",
        "\n",
        "import warnings\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "print(\"Libraries imported.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3mNsVI5eSDOi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API Keys Set:\n",
            "Google API Key set: Yes\n",
            "OpenAI API Key set: Yes\n",
            "Anthropic API Key set: Yes\n"
          ]
        }
      ],
      "source": [
        "# @title Configure API Keys using dotenv\n",
        "\n",
        "# .envファイルから環境変数を読み込むためにdotenvをインポート\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# .envファイルから環境変数を読み込む\n",
        "load_dotenv()\n",
        "\n",
        "# 環境変数からAPIキーを取得\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
        "\n",
        "# 環境変数に設定\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY if GOOGLE_API_KEY else \"YOUR_GOOGLE_API_KEY\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY if OPENAI_API_KEY else \"YOUR_OPENAI_API_KEY\"\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY if ANTHROPIC_API_KEY else \"YOUR_ANTHROPIC_API_KEY\"\n",
        "\n",
        "# --- APIキーの確認 ---\n",
        "print(\"API Keys Set:\")\n",
        "print(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
        "print(f\"OpenAI API Key set: {'Yes' if os.environ.get('OPENAI_API_KEY') and os.environ['OPENAI_API_KEY'] != 'YOUR_OPENAI_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
        "print(f\"Anthropic API Key set: {'Yes' if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'YOUR_ANTHROPIC_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
        "\n",
        "# ADKがVertex AIではなく直接APIキーを使用するように設定\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n",
        "\n",
        "\n",
        "# @markdown **セキュリティに関する注意:** APIキーは安全に管理することがベストプラクティスです（例：Colab Secretsや環境変数を使用）。.envファイルを使用することで、APIキーをコードに直接記述せずに管理できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MI_qvZJrSJuR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Environment configured.\n"
          ]
        }
      ],
      "source": [
        "# --- Define Model Constants for easier use ---\n",
        "\n",
        "MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash\"\n",
        "\n",
        "# Note: Specific model names might change. Refer to LiteLLM/Provider documentation.\n",
        "MODEL_GPT_o3_MINI = \"openai/o3-mini-2025-01-31\"\n",
        "MODEL_CLAUDE_SONNET = \"anthropic/claude-3-sonnet-20240229\"\n",
        "\n",
        "\n",
        "print(\"\\nEnvironment configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7LZM3ysSOMu"
      },
      "source": [
        " ---\n",
        " \n",
        " ## ステップ 1: 最初のエージェント \\- 基本的な天気検索\n",
        " \n",
        " 天気ボットの基本的なコンポーネントを構築することから始めましょう：特定のタスク（天気情報の検索）を実行できる単一のエージェントす。これには、次の2つの主要な部分を作成する必要があります：\n",
        " \n",
        " 1. **ツール:** エージェントに天気データを取得する*能力*を与えるPython関数。  \n",
        " 2. **エージェント:** ユーザーのリクエストを理解し、天気ツールを持っていることを認識し、いつどのようにそれを使用するかを決定するAの「頭脳」。\n",
        " \n",
        " ---\n",
        " \n",
        " **1\\. ツールの定義 (`get_weather`)**\n",
        " \n",
        " ADKでは、**ツール**はエージェントにテキスト生成を超えた具体的な能力を与える構成要素です。これらは通常、APIの呼び出し、データベーの照会、計算の実行など、特定のアクションを実行する通常のPython関数です。\n",
        " \n",
        " 最初のツールは*模擬*天気レポートを提供します。これにより、外部APIキーをまだ必要とせずにエージェント構造に集中できます。後で、この擬関数を実際の天気サービスを呼び出す関数に簡単に置き換えることができます。\n",
        " \n",
        " **重要な概念：ドキュメント文字列（Docstrings）が重要です！** エージェントのLLMは関数の**ドキュメント文字列**に大きく依存して以を理解します：\n",
        " \n",
        " * ツールが*何を*するのか。  \n",
        " * *いつ*使用するのか。  \n",
        " * *どの引数*が必要か（`city: str`）。  \n",
        " * *どのような情報*を返すのか。\n",
        " \n",
        " **ベストプラクティス：** ツールに対して明確で、説明的で、正確なドキュメント文字列を書きましょう。これはLLMがツールを正しく使用すために不可欠です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ILy7YTCbSRAT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ツール: get_weather が都市: New York のために呼び出されました ---\n",
            "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25°C.'}\n",
            "--- ツール: get_weather が都市: Paris のために呼び出されました ---\n",
            "{'status': 'error', 'error_message': \"申し訳ありません。'Paris'の天気情報はありません。\"}\n"
          ]
        }
      ],
      "source": [
        "# @title get_weatherツールを定義する\n",
        "def get_weather(city: str) -> dict:\n",
        "    \"\"\"指定された都市の現在の天気予報を取得します。\n",
        "\n",
        "    引数:\n",
        "        city (str): 都市の名前（例: \"New York\", \"London\", \"Tokyo\"）。\n",
        "        都市名は英語にしてください。\n",
        "\n",
        "    戻り値:\n",
        "        dict: 天気情報を含む辞書。\n",
        "            'status' キー（'success' または 'error'）を含みます。\n",
        "            'success' の場合、天気の詳細を含む 'report' キーを含みます。\n",
        "            'error' の場合、'error_message' キーを含みます。\n",
        "    \"\"\"\n",
        "    print(f\"--- ツール: get_weather が都市: {city} のために呼び出されました ---\") # ツール実行のログ\n",
        "    city_normalized = city.lower().replace(\" \", \"\") # 基本的な正規化\n",
        "\n",
        "    # 模擬天気データ\n",
        "    mock_weather_db = {\n",
        "        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25°C.\"},\n",
        "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15°C.\"},\n",
        "        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18°C.\"},\n",
        "    }\n",
        "\n",
        "    if city_normalized in mock_weather_db:\n",
        "        return mock_weather_db[city_normalized]\n",
        "    else:\n",
        "        return {\"status\": \"error\", \"error_message\": f\"申し訳ありません。'{city}'の天気情報はありません。\"}\n",
        "\n",
        "# ツール使用例（オプションのテスト）\n",
        "print(get_weather(\"New York\"))\n",
        "print(get_weather(\"Paris\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAM0BqGWSTo5"
      },
      "source": [
        " ---\n",
        " \n",
        " **2\\. エージェントの定義 (`weather_agent`)**\n",
        " \n",
        " 次に、**エージェント**自体を作成しましょう。ADKにおける`Agent`は、ユーザー、LLM、利用可能なツール間の相互作用を調整します。\n",
        " \n",
        " 以下のような重要なパラメータで設定します：\n",
        " \n",
        " * `name`: このエージェントの一意の識別子（例：「weather\\_agent\\_v1」）。  \n",
        " * `model`: 使用するLLMを指定します（例：`MODEL_GEMINI_2_5_PRO`）。特定のGeminiモデルから始めます。  \n",
        " * `description`: エージェントの全体的な目的の簡潔な要約。これは後で他のエージェントが*このエージェント*にタスクを委任するかどうを決定する際に重要になります。  \n",
        " * `instruction`: LLMの振る舞い方、ペルソナ、目標、特に割り当てられた`tools`を*どのように、いつ*使用するかについての詳細なガイダス。  \n",
        " * `tools`: エージェントが使用を許可されている実際のPythonツール関数を含むリスト（例：`[get_weather]`）。\n",
        " \n",
        " **ベストプラクティス：** 明確で具体的な`instruction`プロンプトを提供しましょう。指示が詳細であればあるほど、LLMは自分の役割とツルの効果的な使用方法をより理解できます。必要に応じてエラー処理について明示的に記述してください。\n",
        " \n",
        " **ベストプラクティス：** 説明的な`name`と`description`の値を選びましょう。これらはADK内部で使用され、自動委任（後で説明）などの能に不可欠です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6Ho1COmKSUeV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "エージェント 'weather_agent_v1' がモデル 'gemini-2.0-flash' を使用して作成されました。\n"
          ]
        }
      ],
      "source": [
        "# @title 天気エージェントの定義\n",
        "# 前に定義したモデル定数の1つを使用\n",
        "AGENT_MODEL = MODEL_GEMINI_2_0_FLASH # Geminiから始める\n",
        "\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_agent_v1\",\n",
        "    model=AGENT_MODEL, # GeminiのモデルまたはLiteLlmオブジェクトを指定可能\n",
        "    description=\"特定の都市の天気情報を提供します。\",\n",
        "    instruction=\"あなたは役に立つ天気アシスタントです。\"\n",
        "                \"ユーザーが特定の都市の天気を尋ねる場合、\"\n",
        "                \"'get_weather'ツールを使用して情報を取得してください。\"\n",
        "                \"ツールがエラーを返した場合は、丁寧にユーザーに伝えてください。\"\n",
        "                \"ツールが成功した場合は、天気レポートを明確に提示してください。\",\n",
        "    tools=[get_weather], # 関数を直接渡す\n",
        ")\n",
        "\n",
        "print(f\"エージェント '{weather_agent.name}' がモデル '{AGENT_MODEL}' を使用して作成されました。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvz7LDhbSZxL"
      },
      "source": [
        " ---\n",
        " \n",
        " **3\\. Runnerとセッションサービスの設定**\n",
        " \n",
        " 会話を管理しエージェントを実行するために、さらに2つのコンポーネントが必要です：\n",
        " \n",
        " * `SessionService`: 異なるユーザーやセッションの会話履歴と状態を管理する役割を担います。`InMemorySessionService`はすべてをメリに保存するシンプルな実装で、テストやシンプルなアプリケーションに適しています。交換されたメッセージを追跡します。状態の永続化についはステップ4でさらに詳しく説明します。  \n",
        " * `Runner`: 対話フローを調整するエンジンです。ユーザー入力を受け取り、適切なエージェントにルーティングし、エージェントのロジックに基づいてLLMやツールの呼び出しを管理し、`SessionService`を通じてセッションの更新を処理し、対話の進行状況を表すイベントを生成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h30dNtqMSah5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "セッションが作成されました: アプリ='weather_tutorial_app', ユーザー='user_1', セッション='session_001'\n",
            "エージェント 'weather_agent_v1' のランナーが作成されました。\n"
          ]
        }
      ],
      "source": [
        "# @title セッションサービスとランナーの設定\n",
        "\n",
        "# --- セッション管理 ---\n",
        "# 重要概念: SessionServiceは会話履歴と状態を保存します。\n",
        "# InMemorySessionServiceはこのチュートリアル用の単純な非永続的ストレージです。\n",
        "session_service = InMemorySessionService()\n",
        "\n",
        "# 対話コンテキストを識別するための定数を定義\n",
        "APP_NAME = \"weather_tutorial_app\"\n",
        "USER_ID = \"user_1\"\n",
        "SESSION_ID = \"session_001\" # 簡略化のために固定IDを使用\n",
        "\n",
        "# 会話が行われる特定のセッションを作成\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME,\n",
        "    user_id=USER_ID,\n",
        "    session_id=SESSION_ID\n",
        ")\n",
        "print(f\"セッションが作成されました: アプリ='{APP_NAME}', ユーザー='{USER_ID}', セッション='{SESSION_ID}'\")\n",
        "\n",
        "# --- ランナー ---\n",
        "# 重要概念: Runnerはエージェント実行ループを調整します。\n",
        "runner = Runner(\n",
        "    agent=weather_agent, # 実行したいエージェント\n",
        "    app_name=APP_NAME,   # 実行をアプリに関連付ける\n",
        "    session_service=session_service # セッションマネージャーを使用\n",
        ")\n",
        "print(f\"エージェント '{runner.agent.name}' のランナーが作成されました。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zKGVwRkSduA"
      },
      "source": [
        " ---\n",
        " \n",
        " **4\\. エージェントとの対話**\n",
        " \n",
        " エージェントにメッセージを送信し、その応答を受け取る方法が必要です。LLM呼び出しやツールの実行には時間がかかる可能性があるため、ADの`Runner`は非同期で動作します。\n",
        " \n",
        " 以下のような`async`ヘルパー関数（`call_agent_async`）を定義します：\n",
        " \n",
        " 1. ユーザークエリ文字列を受け取ります。  \n",
        " 2. それをADK `Content`形式にパッケージ化します。  \n",
        " 3. ユーザー/セッションコンテキストと新しいメッセージを提供して`runner.run_async`を呼び出します。  \n",
        " 4. ランナーから生成される**イベント**を反復処理します。イベントはエージェントの実行ステップ（例：ツール呼び出し要求、ツール結果信、中間LLM思考、最終応答）を表します。  \n",
        " 5. `event.is_final_response()`を使用して**最終応答**イベントを識別し、表示します。\n",
        " \n",
        " **なぜ`async`なのか？** LLMや潜在的なツール（外部APIなど）とのやり取りはI/O制約のある操作です。`asyncio`を使用することで、実行をブロックすることなくこれらの操作を効率的に処理できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yZJr8lbkSebH"
      },
      "outputs": [],
      "source": [
        "# @title エージェント対話関数の定義\n",
        "\n",
        "from google.genai import types # メッセージのContent/Partsを作成するため\n",
        "\n",
        "async def call_agent_async(query: str, runner, user_id, session_id):\n",
        "   \"\"\"エージェントにクエリを送信し、最終応答を表示します。\"\"\"\n",
        "   print(f\"\\n>>> ユーザークエリ: {query}\")\n",
        "\n",
        "   # ユーザーのメッセージをADK形式で準備\n",
        "   content = types.Content(role='user', parts=[types.Part(text=query)])\n",
        "\n",
        "   final_response_text = \"エージェントは最終応答を生成しませんでした。\" # デフォルト\n",
        "\n",
        "   # 重要概念: run_asyncはエージェントロジックを実行し、イベントを生成します。\n",
        "   # 最終回答を見つけるためにイベントを反復処理します。\n",
        "   async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
        "      # 以下の行のコメントを解除すると、実行中の*すべての*イベントを確認できます\n",
        "      # print(f\"  [イベント] 作成者: {event.author}, タイプ: {type(event).__name__}, 最終: {event.is_final_response()}, 内容: {event.content}\")\n",
        "\n",
        "      # 重要概念: is_final_response()はターンの最終メッセージを示します。\n",
        "      if event.is_final_response():\n",
        "         if event.content and event.content.parts:\n",
        "            # 最初のパートにテキスト応答があると仮定\n",
        "            final_response_text = event.content.parts[0].text\n",
        "         elif event.actions and event.actions.escalate: # エラー/エスカレーションの可能性を処理\n",
        "            final_response_text = f\"エージェントがエスカレーション: {event.error_message or '特定のメッセージなし。'}\"\n",
        "            # 必要に応じてここに他のチェックを追加（例：特定のエラーコードなど）\n",
        "         break # 最終応答が見つかったらイベント処理を停止\n",
        "\n",
        "   print(f\"<<< エージェント応答: {final_response_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6DQSqrqk5ic"
      },
      "source": [
        " ---\n",
        " \n",
        " **5\\. 会話を実行する**\n",
        " \n",
        " 最後に、エージェントにいくつかのクエリを送信して、セットアップをテストしましょう。メイン`async`関数内で`async`呼び出しをラップし、await`を使用して実行します。\n",
        " \n",
        " 出力を観察してください：\n",
        " \n",
        " * ユーザークエリを確認します。\n",
        " * エージェントがツールを使用するときに`--- ツール: get_weather が...のために呼び出されました ---`ログに注目してください。\n",
        " * エージェントの最終応答を観察してください。天気データが利用できない場合（パリの場合）の処理方法も含まれています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mEd2QhHyUKY8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> ユーザークエリ: ロンドンの天気はどうですか？\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ツール: get_weather が都市: London のために呼び出されました ---\n",
            "<<< エージェント応答: ロンドンの天気は曇りで、気温は15℃です。\n",
            "\n",
            ">>> ユーザークエリ: パリはどうですか？\n",
            "--- ツール: get_weather が都市: Paris のために呼び出されました ---\n",
            "<<< エージェント応答: 申し訳ありません。パリの天気情報を取得できませんでした。\n",
            "\n",
            ">>> ユーザークエリ: ニューヨークの天気を教えてください\n",
            "--- ツール: get_weather が都市: New York のために呼び出されました ---\n",
            "<<< エージェント応答: ニューヨークの天気は晴れで、気温は25℃です。\n"
          ]
        }
      ],
      "source": [
        "# @title 初期会話の実行\n",
        "\n",
        "# 対話ヘルパーを待機するための非同期関数が必要です\n",
        "async def run_conversation():\n",
        "    await call_agent_async(\"ロンドンの天気はどうですか？\",\n",
        "                                        runner=runner,\n",
        "                                        user_id=USER_ID,\n",
        "                                        session_id=SESSION_ID)\n",
        "\n",
        "    await call_agent_async(\"パリはどうですか？\",\n",
        "                                        runner=runner,\n",
        "                                        user_id=USER_ID,\n",
        "                                        session_id=SESSION_ID) # ツールのエラーメッセージを期待\n",
        "\n",
        "    await call_agent_async(\"ニューヨークの天気を教えてください\",\n",
        "                                        runner=runner,\n",
        "                                        user_id=USER_ID,\n",
        "                                        session_id=SESSION_ID)\n",
        "\n",
        "# 非同期コンテキスト（ColabやJupyterなど）でawaitを使用して会話を実行\n",
        "await run_conversation()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbUzAGvsmB2a"
      },
      "source": [
        " ---\n",
        " \n",
        " おめでとうございます！最初のADKエージェントの構築と対話に成功しました。エージェントはユーザーのリクエストを理解し、ツールを使用し情報を検索し、ツールの結果に基づいて適切に応答します。\n",
        " \n",
        " 次のステップでは、このエージェントを動かす基盤となる言語モデルを簡単に切り替える方法を探ります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEPaI-beSh8P"
      },
      "source": [
        " ## ステップ2: LiteLLMを使用したマルチモデル対応\n",
        " ステップ1では、特定のGeminiモデルを利用した機能的な天気エージェントを構築しました。これは効果的ですが、実際のアプリケーションでは*異なる*大規模言語モデル（LLM）を使用する柔軟性が役立つことがよくあります。なぜでしょうか？\n",
        " * **パフォーマンス:** 一部のモデルは特定のタスク（例：コーディング、推論、創造的な文章作成）に優れています。\n",
        " * **コスト:** モデルによって価格設定が異なります。\n",
        " * **機能:** モデルは多様な機能、コンテキストウィンドウサイズ、微調整オプションを提供します。\n",
        " * **可用性/冗長性:** 代替手段を持つことで、あるプロバイダーに問題が発生しても、アプリケーションが機能し続けることを保証します。\n",
        " ADKは[**LiteLLM**](https://github.com/BerriAI/litellm)ライブラリとの統合を通じて、モデル間の切り替えをシームレスにします。LiteLLMは100以上の異なるLLMへの一貫したインターフェースとして機能します。\n",
        " **このステップでは以下を行います：**\n",
        " 1. `LiteLlm`ラッパーを使用して、OpenAI（GPT）やAnthropic（Claude）などのプロバイダーからモデルを使用するようにADK `Agent`を設定する方法を学びます。\n",
        " 2. 天気エージェントのインスタンスを定義、設定（それぞれ独自のセッションとランナーを持つ）し、それぞれ異なるLLMによってサポートされたものをすぐにテストします。\n",
        " 3. これらの異なるエージェントと対話して、同じ基本ツールを使用していても、応答の潜在的な違いを観察します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvfhdrCDnPMn"
      },
      "source": [
        "---\n",
        "\n",
        "**1\\. Import `LiteLlm`**\n",
        "\n",
        "We imported this during the initial setup (Step 0), but it's the key component for multi-model support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mPBr56NSnMje"
      },
      "outputs": [],
      "source": [
        "# @title 1. Import LiteLlm\n",
        "from google.adk.models.lite_llm import LiteLlm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoUbe1mZnXd9"
      },
      "source": [
        " **2\\. マルチモデルエージェントの定義とテスト**\n",
        " \n",
        " モデル名の文字列だけを渡す（デフォルトではGoogleのGeminiモデルが使用される）代わりに、希望するモデル識別子文字列を`LiteLlm`クラス内でラップします。\n",
        " \n",
        " *   **重要な概念：`LiteLlm`ラッパー：** `LiteLlm(model=\"provider/model_name\")`構文は、このエージェントへのリクエストを指定されたモデルプロバイダーにLiteLLMライブラリを通じてルーティングするようADKに指示します。\n",
        " \n",
        " ステップ0で、OpenAIとAnthropicに必要なAPIキーを設定したことを確認してください。セットアップ直後に各エージェントと対話するために、`call_agent_async`関数（以前に定義され、現在は`runner`、`user_id`、`session_id`を受け入れる）を使用します。\n",
        " \n",
        " 以下の各ブロックでは：\n",
        " *   特定のLiteLLMモデル（`MODEL_GPT_o3_MINI`または`MODEL_CLAUDE_SONNET`）を使用してエージェントを定義します。\n",
        " *   そのエージェントのテスト実行専用の*新しい、個別の*`InMemorySessionService`とセッションを作成します。これにより、このデモンストレーションの会話履歴が分離されます。\n",
        " *   特定のエージェントとそのセッションサービス用に設定された`Runner`を作成します。\n",
        " *   すぐに`call_agent_async`を呼び出してクエリを送信し、エージェントをテストします。\n",
        " \n",
        " **ベストプラクティス：** モデル名には定数（ステップ0で定義された`MODEL_GPT_o3_MINI`、`MODEL_CLAUDE_SONNET`など）を使用して、タイプミスを防ぎ、コードを管理しやすくします。\n",
        " \n",
        " **エラー処理：** エージェント定義を`try...except`ブロックでラップします。これにより、特定のプロバイダーのAPIキーが欠落しているか無効な場合でも、コードセル全体が失敗するのを防ぎ、設定されている*モデル*でチュートリアルを続行できます。\n",
        " \n",
        " まず、OpenAIのGPT-4oを使用してエージェントを作成しテストしましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "C2WvKj4_Sp2J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "エージェント 'weather_agent_gpt' がモデル 'openai/o3-mini-2025-01-31' を使用して作成されました。\n",
            "セッションが作成されました: アプリ='weather_tutorial_app_gpt', ユーザー='user_1_gpt', セッション='session_001_gpt'\n",
            "エージェント 'weather_agent_gpt' 用のランナーが作成されました。\n",
            "\n",
            "--- GPTエージェントのテスト ---\n",
            "\n",
            ">>> ユーザークエリ: 東京の天気はどうですか？\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ツール: get_weather が都市: Tokyo のために呼び出されました ---\n",
            "<<< エージェント応答: 東京は現在、軽い雨が降っており、気温は約18°Cです。\n"
          ]
        }
      ],
      "source": [
        "# @title GPTエージェントの定義とテスト\n",
        "\n",
        "# ステップ1で定義した'get_weather'関数が環境内に定義されていることを確認してください。\n",
        "# 以前に定義した'call_agent_async'が定義されていることを確認してください。\n",
        "\n",
        "# --- GPT-4oを使用したエージェント ---\n",
        "weather_agent_gpt = None # Noneで初期化\n",
        "runner_gpt = None      # ランナーをNoneで初期化\n",
        "\n",
        "try:\n",
        "    weather_agent_gpt = Agent(\n",
        "        name=\"weather_agent_gpt\",\n",
        "        # 重要な変更: LiteLLMモデル識別子をラップする\n",
        "        model=LiteLlm(model=MODEL_GPT_o3_MINI),\n",
        "        description=\"天気情報を提供します（GPT-4oを使用）。\",\n",
        "        instruction=\"あなたはGPT-4oを搭載した役立つ天気アシスタントです。\"\n",
        "                    \"都市の天気リクエストには'get_weather'ツールを使用してください。\"\n",
        "                    \"ツールの出力ステータスに基づいて、成功したレポートや丁寧なエラーメッセージを明確に提示してください。\",\n",
        "        tools=[get_weather], # 同じツールを再利用\n",
        "    )\n",
        "    print(f\"エージェント '{weather_agent_gpt.name}' がモデル '{MODEL_GPT_o3_MINI}' を使用して作成されました。\")\n",
        "\n",
        "    # InMemorySessionServiceは、このチュートリアル用のシンプルな非永続的ストレージです。\n",
        "    session_service_gpt = InMemorySessionService() # 専用のサービスを作成\n",
        "\n",
        "    # インタラクションコンテキストを識別するための定数を定義\n",
        "    APP_NAME_GPT = \"weather_tutorial_app_gpt\" # このテスト用のユニークなアプリ名\n",
        "    USER_ID_GPT = \"user_1_gpt\"\n",
        "    SESSION_ID_GPT = \"session_001_gpt\" # シンプルにするために固定IDを使用\n",
        "\n",
        "    # 会話が行われる特定のセッションを作成\n",
        "    session_gpt = session_service_gpt.create_session(\n",
        "        app_name=APP_NAME_GPT,\n",
        "        user_id=USER_ID_GPT,\n",
        "        session_id=SESSION_ID_GPT\n",
        "    )\n",
        "    print(f\"セッションが作成されました: アプリ='{APP_NAME_GPT}', ユーザー='{USER_ID_GPT}', セッション='{SESSION_ID_GPT}'\")\n",
        "\n",
        "    # このエージェントとそのセッションサービス専用のランナーを作成\n",
        "    runner_gpt = Runner(\n",
        "        agent=weather_agent_gpt,\n",
        "        app_name=APP_NAME_GPT,       # 特定のアプリ名を使用\n",
        "        session_service=session_service_gpt # 特定のセッションサービスを使用\n",
        "        )\n",
        "    print(f\"エージェント '{runner_gpt.agent.name}' 用のランナーが作成されました。\")\n",
        "\n",
        "    # --- GPTエージェントのテスト ---\n",
        "    print(\"\\n--- GPTエージェントのテスト ---\")\n",
        "    # call_agent_asyncが正しいランナー、user_id、session_idを使用していることを確認\n",
        "    await call_agent_async(query = \"東京の天気はどうですか？\",\n",
        "                            runner=runner_gpt,\n",
        "                            user_id=USER_ID_GPT,\n",
        "                            session_id=SESSION_ID_GPT)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ GPTエージェント '{MODEL_GPT_o3_MINI}' の作成または実行ができませんでした。APIキーとモデル名を確認してください。エラー: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu_OHirKWFXN"
      },
      "source": [
        "Next, we'll do the same for Anthropic's Claude Sonnet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zqJIS4_nhoh"
      },
      "outputs": [],
      "source": [
        "# @title Define and Test Claude Agent\n",
        "\n",
        "# Make sure 'get_weather' function from Step 1 is defined in your environment.\n",
        "# Make sure 'call_agent_async' is defined from earlier.\n",
        "\n",
        "# --- Agent using Claude Sonnet ---\n",
        "weather_agent_claude = None # Initialize to None\n",
        "runner_claude = None      # Initialize runner to None\n",
        "\n",
        "try:\n",
        "    weather_agent_claude = Agent(\n",
        "        name=\"weather_agent_claude\",\n",
        "        # Key change: Wrap the LiteLLM model identifier\n",
        "        model=LiteLlm(model=MODEL_CLAUDE_SONNET),\n",
        "        description=\"Provides weather information (using Claude Sonnet).\",\n",
        "        instruction=\"You are a helpful weather assistant powered by Claude Sonnet. \"\n",
        "                    \"Use the 'get_weather' tool for city weather requests. \"\n",
        "                    \"Analyze the tool's dictionary output ('status', 'report'/'error_message'). \"\n",
        "                    \"Clearly present successful reports or polite error messages.\",\n",
        "        tools=[get_weather], # Re-use the same tool\n",
        "    )\n",
        "    print(f\"Agent '{weather_agent_claude.name}' created using model '{MODEL_CLAUDE_SONNET}'.\")\n",
        "\n",
        "    # InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
        "    session_service_claude = InMemorySessionService() # Create a dedicated service\n",
        "\n",
        "    # Define constants for identifying the interaction context\n",
        "    APP_NAME_CLAUDE = \"weather_tutorial_app_claude\" # Unique app name\n",
        "    USER_ID_CLAUDE = \"user_1_claude\"\n",
        "    SESSION_ID_CLAUDE = \"session_001_claude\" # Using a fixed ID for simplicity\n",
        "\n",
        "    # Create the specific session where the conversation will happen\n",
        "    session_claude = session_service_claude.create_session(\n",
        "        app_name=APP_NAME_CLAUDE,\n",
        "        user_id=USER_ID_CLAUDE,\n",
        "        session_id=SESSION_ID_CLAUDE\n",
        "    )\n",
        "    print(f\"Session created: App='{APP_NAME_CLAUDE}', User='{USER_ID_CLAUDE}', Session='{SESSION_ID_CLAUDE}'\")\n",
        "\n",
        "    # Create a runner specific to this agent and its session service\n",
        "    runner_claude = Runner(\n",
        "        agent=weather_agent_claude,\n",
        "        app_name=APP_NAME_CLAUDE,       # Use the specific app name\n",
        "        session_service=session_service_claude # Use the specific session service\n",
        "        )\n",
        "    print(f\"Runner created for agent '{runner_claude.agent.name}'.\")\n",
        "\n",
        "    # --- Test the Claude Agent ---\n",
        "    print(\"\\n--- Testing Claude Agent ---\")\n",
        "    # Ensure call_agent_async uses the correct runner, user_id, session_id\n",
        "    await call_agent_async(query = \"Weather in London please.\",\n",
        "                           runner=runner_claude,\n",
        "                           user_id=USER_ID_CLAUDE,\n",
        "                           session_id=SESSION_ID_CLAUDE)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not create or run Claude agent '{MODEL_CLAUDE_SONNET}'. Check API Key and model name. Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsroj8NzWMU9"
      },
      "source": [
        " 両方のコードブロックの出力を注意深く観察してください。以下のことが確認できるはずです：\n",
        " \n",
        " 1.  各エージェント（`weather_agent_gpt`、`weather_agent_claude`）は（APIキーが有効であれば）正常に作成されます。\n",
        " 2.  各エージェント専用のセッションとランナーが設定されています。\n",
        " 3.  各エージェントはクエリを処理する際に`get_weather`ツールを使用する必要性を正しく識別します（`--- Tool: get_weather called... ---`というログが表示されます）。\n",
        " 4.  *基盤となるツールのロジック*は同一のままで、常に私たちのモックデータを返します。\n",
        " 5.  ただし、各エージェントが生成する**最終的なテキスト応答**は、表現、トーン、フォーマットにわずかな違いがある場合があります。これは、指示プロンプトが異なるLLM（GPT-4oとClaude Sonnet）によって解釈され実行されるためです。\n",
        " \n",
        " このステップは、ADK + LiteLLMが提供するパワーと柔軟性を示しています。コアアプリケーションロジック（ツール、基本的なエージェント構造）を一貫させながら、さまざまなLLMを使用してエージェントを簡単に実験し、デプロイすることができます。\n",
        " \n",
        " 次のステップでは、単一のエージェントを超えて、エージェントが互いにタスクを委任できる小さなチームを構築します！\n",
        " \n",
        " ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL5estZ_VKki"
      },
      "source": [
        " ## ステップ3: エージェントチームの構築 \\- 挨拶と別れの委任\n",
        " ステップ1と2では、天気検索のみに焦点を当てた単一のエージェントを構築し実験しました。特定のタスクには効果的ですが、実際のアプリケーションではより多様なユーザーとのやり取りを処理する必要があります。単一の天気エージェントにさらにツールや複雑な指示を追加することも*できますが*、これはすぐに管理が難しくなり、効率が低下する可能性があります。\n",
        " より堅牢なアプローチは**エージェントチーム**を構築することです。これには以下が含まれます：\n",
        " 1. 複数の**専門エージェント**を作成し、それぞれが特定の機能（例：天気用、挨拶用、計算用）のために設計されています。\n",
        " 2. 最初のユーザーリクエストを受け取る**ルートエージェント**（またはオーケストレーター）を指定します。\n",
        " 3. ルートエージェントがユーザーの意図に基づいて、最も適切な専門サブエージェントにリクエストを**委任**できるようにします。\n",
        " **なぜエージェントチームを構築するのか？**\n",
        " * **モジュール性：** 個々のエージェントの開発、テスト、保守が容易になります。\n",
        " * **専門化：** 各エージェントは特定のタスクに合わせて微調整（指示、モデル選択）できます。\n",
        " * **拡張性：** 新しいエージェントを追加することで、新しい機能を簡単に追加できます。\n",
        " * **効率性：** より単純なタスク（挨拶など）には、潜在的により単純/安価なモデルを使用できます。\n",
        " **このステップでは以下を行います：**\n",
        " 1. 挨拶（`say_hello`）と別れ（`say_goodbye`）を処理するための単純なツールを定義します。\n",
        " 2. `greeting_agent`と`farewell_agent`という2つの新しい専門サブエージェントを作成します。\n",
        " 3. メインの天気エージェント（`weather_agent_v2`）を**ルートエージェント**として機能するように更新します。\n",
        " 4. ルートエージェントをサブエージェントで構成し、**自動委任**を可能にします。\n",
        " 5. ルートエージェントにさまざまなタイプのリクエストを送信して、委任フローをテストします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLpXYXxppB4S"
      },
      "source": [
        "---\n",
        "\n",
        "**1\\. Define Tools for Sub-Agents**\n",
        "\n",
        "First, let's create the simple Python functions that will serve as tools for our new specialist agents. Remember, clear docstrings are vital for the agents that will use them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Qc7dHr4ZVM6X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "挨拶と別れのツールが定義されました。\n",
            "--- ツール: say_hello が name: アリス で呼び出されました ---\n",
            "こんにちは、アリスさん！\n",
            "--- ツール: say_goodbye が呼び出されました ---\n",
            "さようなら！良い一日を。\n"
          ]
        }
      ],
      "source": [
        "# @title 挨拶と別れのエージェント用ツールを定義する\n",
        "\n",
        "# ステップ1の'get_weather'が独立して実行する場合に利用可能であることを確認してください。\n",
        "# def get_weather(city: str) -> dict: ... (ステップ1から)\n",
        "\n",
        "def say_hello(name: str = \"there\") -> str:\n",
        "    \"\"\"ユーザーに簡単な挨拶を提供し、オプションで名前で呼びかけます。\n",
        "\n",
        "    Args:\n",
        "        name (str, optional): 挨拶する相手の名前。デフォルトは \"there\"。\n",
        "\n",
        "    Returns:\n",
        "        str: 友好的な挨拶メッセージ。\n",
        "    \"\"\"\n",
        "    print(f\"--- ツール: say_hello が name: {name} で呼び出されました ---\")\n",
        "    return f\"こんにちは、{name}さん！\"\n",
        "\n",
        "def say_goodbye() -> str:\n",
        "    \"\"\"会話を締めくくるための簡単な別れのメッセージを提供します。\"\"\"\n",
        "    print(f\"--- ツール: say_goodbye が呼び出されました ---\")\n",
        "    return \"さようなら！良い一日を。\"\n",
        "\n",
        "print(\"挨拶と別れのツールが定義されました。\")\n",
        "\n",
        "# オプションの自己テスト\n",
        "print(say_hello(\"アリス\"))\n",
        "print(say_goodbye())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkv34_tMVPG3"
      },
      "source": [
        " ---\n",
        " \n",
        " **2\\. サブエージェントの定義（挨拶と別れ）**\n",
        " \n",
        " ここで、専門家のための`Agent`インスタンスを作成します。彼らの非常に焦点を絞った`instruction`と、重要なことに、明確な`description`に注目してください。`description`は*ルートエージェント*が*いつ*これらのサブエージェントに委任するかを決定するための主要な情報です。\n",
        " \n",
        " これらのサブエージェントに異なるLLMを使用することもできます！挨拶エージェントにはGPT-4oを割り当て、別れエージェントもGPT-4oを使用したままにしましょう（必要に応じてAPIキーが設定されていれば、一方をClaudeやGeminiに簡単に切り替えることができます）。\n",
        " \n",
        " **ベストプラクティス:** サブエージェントの`description`フィールドは、その特定の能力を正確かつ簡潔に要約する必要があります。これは効果的な自動委任のために非常に重要です。\n",
        " \n",
        " **ベストプラクティス:** サブエージェントの`instruction`フィールドは、その限られた範囲に合わせて調整し、何をすべきか、そして何をすべきでないか（例：「あなたの*唯一の*タスクは...」）を正確に伝える必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tgT7P1doVRA0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ エージェント 'greeting_agent' がモデル 'openai/o3-mini-2025-01-31' を使用して作成されました。\n",
            "✅ エージェント 'farewell_agent' がモデル 'openai/o3-mini-2025-01-31' を使用して作成されました。\n"
          ]
        }
      ],
      "source": [
        "# @title 挨拶と別れのサブエージェントを定義する\n",
        "\n",
        "# LiteLlmがインポートされ、APIキーが設定されていることを確認（ステップ0/2から）\n",
        "# from google.adk.models.lite_llm import LiteLlm\n",
        "# MODEL_GPT_o3_MINI, MODEL_CLAUDE_SONNET などが定義されているはず\n",
        "\n",
        "# --- 挨拶エージェント ---\n",
        "greeting_agent = None\n",
        "try:\n",
        "    greeting_agent = Agent(\n",
        "        # シンプルなタスクには、より安価な可能性のあるモデルを使用\n",
        "        model=LiteLlm(model=MODEL_GPT_o3_MINI),\n",
        "        name=\"greeting_agent\",\n",
        "        instruction=\"あなたは挨拶エージェントです。あなたの唯一のタスクはユーザーに友好的な挨拶を提供することです。\"\n",
        "                    \"'say_hello'ツールを使用して挨拶を生成してください。\"\n",
        "                    \"ユーザーが名前を提供した場合は、必ずそれをツールに渡してください。\"\n",
        "                    \"他の会話やタスクには関与しないでください。\",\n",
        "        description=\"'say_hello'ツールを使用してシンプルな挨拶を処理します。\", # 委任に重要\n",
        "        tools=[say_hello],\n",
        "    )\n",
        "    print(f\"✅ エージェント '{greeting_agent.name}' がモデル '{MODEL_GPT_o3_MINI}' を使用して作成されました。\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 挨拶エージェントを作成できませんでした。APIキー ({MODEL_GPT_o3_MINI}) を確認してください。エラー: {e}\")\n",
        "\n",
        "# --- 別れエージェント ---\n",
        "farewell_agent = None\n",
        "try:\n",
        "    farewell_agent = Agent(\n",
        "        # 同じまたは異なるモデルを使用可能\n",
        "        model=LiteLlm(model=MODEL_GPT_o3_MINI), # この例ではGPTを使用\n",
        "        name=\"farewell_agent\",\n",
        "        instruction=\"あなたは別れエージェントです。あなたの唯一のタスクは丁寧な別れのメッセージを提供することです。\"\n",
        "                    \"ユーザーが会話を終了する意思を示した場合（例：「さようなら」、「バイバイ」、「ありがとう、さようなら」、「また会いましょう」などの言葉を使用）、\"\n",
        "                    \"'say_goodbye'ツールを使用してください。\"\n",
        "                    \"他のアクションは実行しないでください。\",\n",
        "        description=\"'say_goodbye'ツールを使用してシンプルな別れの挨拶を処理します。\", # 委任に重要\n",
        "        tools=[say_goodbye],\n",
        "    )\n",
        "    print(f\"✅ エージェント '{farewell_agent.name}' がモデル '{MODEL_GPT_o3_MINI}' を使用して作成されました。\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 別れエージェントを作成できませんでした。APIキー ({MODEL_GPT_o3_MINI}) を確認してください。エラー: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFL_TLFPVS5P"
      },
      "source": [
        " ---\n",
        " \n",
        " **3\\. ルートエージェント（Weather Agent v2）とサブエージェントの定義**\n",
        " \n",
        " ここで、`weather_agent`をアップグレードします。主な変更点は以下の通りです：\n",
        " \n",
        " * `sub_agents`パラメータの追加：先ほど作成した`greeting_agent`と`farewell_agent`のインスタンスを含むリストを渡します。\n",
        " * `instruction`の更新：ルートエージェントに対して、そのサブエージェントについて*明示的に*伝え、*いつ*タスクを委任すべきかを指示します。\n",
        " \n",
        " **重要概念：自動委任（Auto Flow）** `sub_agents`リストを提供することで、ADKは自動委任を可能にします。ルートエージェントがユーザークエリを受け取ると、そのLLMは自身の指示とツールだけでなく、各サブエージェントの`description`も考慮します。LLMがクエリがサブエージェントの説明された能力（例：「シンプルな挨拶を処理する」）により適合すると判断した場合、そのターンで*制御を移す*ための特別な内部アクションを自動的に生成します。サブエージェントはその後、独自のモデル、指示、ツールを使用してクエリを処理します。\n",
        " \n",
        " **ベストプラクティス：** ルートエージェントの指示が委任の決定を明確に導くようにしてください。サブエージェントを名前で言及し、委任が発生すべき条件を説明してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nniWunchVV8_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ ルートエージェント 'weather_agent_v2' がモデル 'model='openai/o3-mini-2025-01-31' llm_client=<google.adk.models.lite_llm.LiteLLMClient object at 0x7f9afa82f740>' を使用して作成されました。サブエージェント: ['greeting_agent', 'farewell_agent']\n"
          ]
        }
      ],
      "source": [
        "# @title ルートエージェントとサブエージェントの定義\n",
        "\n",
        "# サブエージェントが正常に作成されていることと、元の'get_weather'ツールが定義されていることを確認します。\n",
        "root_agent = None\n",
        "runner_root = None # ランナーを初期化\n",
        "\n",
        "if greeting_agent and farewell_agent and 'get_weather' in globals():\n",
        "    # オーケストレーションを処理するために高性能なO3モデルを使用しましょう\n",
        "    root_agent_model = LiteLlm(model=MODEL_GPT_o3_MINI)\n",
        "\n",
        "    weather_agent_team = Agent(\n",
        "        name=\"weather_agent_v2\", # 新しいバージョン名を付ける\n",
        "        model=root_agent_model,\n",
        "        description=\"メインコーディネーターエージェント。天気リクエストを処理し、挨拶/別れを専門家に委任します。\",\n",
        "        instruction=\"あなたはチームを調整するメイン天気エージェントです。あなたの主な責任は天気情報を提供することです。\"\n",
        "                    \"特定の天気リクエスト（例：「ロンドンの天気」）に対してのみ'get_weather'ツールを使用してください。\"\n",
        "                    \"あなたには専門のサブエージェントがいます：\"\n",
        "                    \"1. 'greeting_agent'：「こんにちは」、「やあ」などの簡単な挨拶を処理します。これらの場合は委任してください。\"\n",
        "                    \"2. 'farewell_agent'：「さようなら」、「また会いましょう」などの簡単な別れを処理します。これらの場合は委任してください。\"\n",
        "                    \"ユーザーのクエリを分析してください。挨拶の場合は'greeting_agent'に委任し、別れの場合は'farewell_agent'に委任してください。\"\n",
        "                    \"天気のリクエストの場合は、'get_weather'を使用して自分自身で処理してください。\"\n",
        "                    \"それ以外の場合は、適切に応答するか、対応できないことを述べてください。\",\n",
        "        tools=[get_weather], # ルートエージェントは主要タスクのために天気ツールが必要\n",
        "        # 重要な変更：ここでサブエージェントをリンク！\n",
        "        sub_agents=[greeting_agent, farewell_agent]\n",
        "    )\n",
        "    print(f\"✅ ルートエージェント '{weather_agent_team.name}' がモデル '{root_agent_model}' を使用して作成されました。サブエージェント: {[sa.name for sa in weather_agent_team.sub_agents]}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ 1つ以上のサブエージェントが初期化に失敗したか、'get_weather'ツールが見つからないため、ルートエージェントを作成できません。\")\n",
        "    if not greeting_agent: print(\" - 挨拶エージェントが見つかりません。\")\n",
        "    if not farewell_agent: print(\" - 別れエージェントが見つかりません。\")\n",
        "    if 'get_weather' not in globals(): print(\" - get_weather関数が見つかりません。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg-IjZYVVYXe"
      },
      "source": [
        " ---\n",
        " \n",
        " **4\\. エージェントチームとの対話**\n",
        " \n",
        " ルートエージェント（`weather_agent_team` - *注意：この変数名が前のコードブロックで定義されたものと一致していることを確認してください。おそらく `# @title ルートエージェントとサブエージェントの定義` で `root_agent` という名前になっているかもしれません*）を専門のサブエージェントと共に定義したので、委任メカニズムをテストしましょう。\n",
        " \n",
        " 次のコードブロックでは：\n",
        " \n",
        " 1.  `async`関数 `run_team_conversation` を定義します。\n",
        " 2.  この関数内で、このテスト実行専用の*新しい専用* `InMemorySessionService` と特定のセッション（`session_001_agent_team`）を作成します。これにより、チームダイナミクスをテストするための会話履歴が分離されます。\n",
        " 3.  `Runner`（`runner_agent_team`）を作成し、`weather_agent_team`（ルートエージェント）と専用セッションサービスを使用するように構成します。\n",
        " 4.  更新された `call_agent_async` 関数を使用して、異なるタイプのクエリ（挨拶、天気リクエスト、別れ）を `runner_agent_team` に送信します。このテスト専用にランナー、ユーザーID、セッションIDを明示的に渡します。\n",
        " 5.  `run_team_conversation` 関数をすぐに実行します。\n",
        " \n",
        " 予想されるフローは次のとおりです：\n",
        " \n",
        " 1.  「こんにちは！」というクエリが `runner_agent_team` に送られます。\n",
        " 2.  ルートエージェント（`weather_agent_team`）がそれを受け取り、その指示と `greeting_agent` の説明に基づいて、タスクを委任します。\n",
        " 3.  `greeting_agent` がクエリを処理し、`say_hello` ツールを呼び出して、応答を生成します。\n",
        " 4.  「ニューヨークの天気は？」というクエリは委任*されず*、ルートエージェントが直接 `get_weather` ツールを使用して処理します。\n",
        " 5.  「ありがとう、さようなら！」というクエリは `farewell_agent` に委任され、`say_goodbye` ツールを使用します。\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "t9Wy4ai8VZ7H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- エージェントチーム委任のテスト ---\n",
            "セッション作成: アプリ='weather_tutorial_agent_team', ユーザー='user_1_agent_team', セッション='session_001_agent_team'\n",
            "エージェント 'weather_agent_v2' のランナーが作成されました。\n",
            "\n",
            ">>> ユーザークエリ: こんにちは！\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ツール: say_hello が name:  で呼び出されました ---\n",
            "<<< エージェント応答: こんにちは、さん！\n",
            "\n",
            ">>> ユーザークエリ: ニューヨークの天気は？\n",
            "--- ツール: get_weather が都市: ニューヨーク のために呼び出されました ---\n",
            "<<< エージェント応答: 申し訳ありませんが、ニューヨークの天気情報が見つかりませんでした。\n",
            "\n",
            ">>> ユーザークエリ: ありがとう、さようなら！\n",
            "--- ツール: say_goodbye が呼び出されました ---\n",
            "--- ツール: say_goodbye が呼び出されました ---\n",
            "<<< エージェント応答: さようなら！またお会いできる日を楽しみにしています。\n"
          ]
        }
      ],
      "source": [
        "# @title エージェントチームとの対話\n",
        "\n",
        "# ルートエージェント（前のセルの 'weather_agent_team' または 'root_agent'）が定義されていることを確認します。\n",
        "# call_agent_async 関数が定義されていることを確認します。\n",
        "\n",
        "# ルートエージェント変数が存在するか確認してから会話関数を定義します\n",
        "root_agent_var_name = 'root_agent' # ステップ3ガイドからのデフォルト名\n",
        "if 'weather_agent_team' in globals(): # ユーザーが代わりにこの名前を使用したか確認\n",
        "    root_agent_var_name = 'weather_agent_team'\n",
        "elif 'root_agent' not in globals():\n",
        "    print(\"⚠️ ルートエージェント（'root_agent'または'weather_agent_team'）が見つかりません。run_team_conversationを定義できません。\")\n",
        "    # コードブロックが実行された場合にNameErrorを防ぐためのダミー値を割り当て\n",
        "    root_agent = None\n",
        "\n",
        "if root_agent_var_name in globals() and globals()[root_agent_var_name]:\n",
        "    async def run_team_conversation():\n",
        "        print(\"\\n--- エージェントチーム委任のテスト ---\")\n",
        "        # InMemorySessionServiceは、このチュートリアル用のシンプルな非永続的ストレージです。\n",
        "        session_service = InMemorySessionService()\n",
        "\n",
        "        # インタラクションコンテキストを識別するための定数を定義\n",
        "        APP_NAME = \"weather_tutorial_agent_team\"\n",
        "        USER_ID = \"user_1_agent_team\"\n",
        "        SESSION_ID = \"session_001_agent_team\" # 簡略化のために固定IDを使用\n",
        "\n",
        "        # 会話が行われる特定のセッションを作成\n",
        "        session = session_service.create_session(\n",
        "            app_name=APP_NAME,\n",
        "            user_id=USER_ID,\n",
        "            session_id=SESSION_ID\n",
        "        )\n",
        "        print(f\"セッション作成: アプリ='{APP_NAME}', ユーザー='{USER_ID}', セッション='{SESSION_ID}'\")\n",
        "\n",
        "        # --- 実際のルートエージェントオブジェクトを取得 ---\n",
        "        # 決定された変数名を使用\n",
        "        actual_root_agent = globals()[root_agent_var_name]\n",
        "\n",
        "        # このエージェントチームテスト専用のランナーを作成\n",
        "        runner_agent_team = Runner(\n",
        "            agent=actual_root_agent, # ルートエージェントオブジェクトを使用\n",
        "            app_name=APP_NAME,       # 特定のアプリ名を使用\n",
        "            session_service=session_service # 特定のセッションサービスを使用\n",
        "            )\n",
        "        # 実際のルートエージェントの名前を表示するための修正されたprint文\n",
        "        print(f\"エージェント '{actual_root_agent.name}' のランナーが作成されました。\")\n",
        "\n",
        "        # 常に正しいIDを渡してルートエージェントのランナーを介して対話\n",
        "        await call_agent_async(query = \"こんにちは！\",\n",
        "                                runner=runner_agent_team,\n",
        "                                user_id=USER_ID,\n",
        "                                session_id=SESSION_ID)\n",
        "        await call_agent_async(query = \"ニューヨークの天気は？\",\n",
        "                                runner=runner_agent_team,\n",
        "                                user_id=USER_ID,\n",
        "                                session_id=SESSION_ID)\n",
        "        await call_agent_async(query = \"ありがとう、さようなら！\",\n",
        "                                runner=runner_agent_team,\n",
        "                                user_id=USER_ID,\n",
        "                                session_id=SESSION_ID)\n",
        "\n",
        "    # 会話を実行\n",
        "    # 注意: ルートおよびサブエージェントで使用されるモデルのAPIキーが必要かもしれません！\n",
        "    await run_team_conversation()\n",
        "else:\n",
        "    print(\"\\n⚠️ 前のステップでルートエージェントが正常に定義されなかったため、エージェントチーム会話をスキップします。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgw3Cn2NVcI7"
      },
      "source": [
        " ---\n",
        " \n",
        " 出力ログをよく見てください。特に `--- Tool: ... called ---` メッセージに注目してください。以下のことが確認できるはずです：\n",
        " \n",
        " *   「こんにちは！」に対して、`say_hello` ツールが呼び出されました（`greeting_agent` が処理したことを示しています）。\n",
        " *   「ニューヨークの天気は？」に対して、`get_weather` ツールが呼び出されました（ルートエージェントが処理したことを示しています）。\n",
        " *   「ありがとう、さようなら！」に対して、`say_goodbye` ツールが呼び出されました（`farewell_agent` が処理したことを示しています）。\n",
        " \n",
        " これにより、**自動委任**が成功したことが確認できます！ルートエージェントは、その指示と `sub_agents` の `description` に導かれて、ユーザーのリクエストをチーム内の適切な専門エージェントに正しく振り分けました。\n",
        " \n",
        " これで、複数のエージェントが連携するアプリケーション構造を作成できました。このモジュラー設計は、より複雑で高機能なエージェントシステムを構築するための基本です。次のステップでは、セッション状態を使用してターン間で情報を記憶する能力をエージェントに与えます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7gD2sCy1qWz"
      },
      "source": [
        " ## ステップ4: セッション状態を使用したメモリと個人化の追加\n",
        " \n",
        " これまで、エージェントチームは委任を通じて異なるタスクを処理できましたが、各対話は新しく始まります - エージェントはセッション内の過去の会話やユーザー設定を記憶していません。より洗練されたコンテキスト対応の体験を作成するために、エージェントには**メモリ**が必要です。ADKはこれを**セッション状態**を通じて提供します。\n",
        " \n",
        " **セッション状態とは？**\n",
        " \n",
        " * 特定のユーザーセッション（`APP_NAME`、`USER_ID`、`SESSION_ID`で識別）に紐づけられたPythonディクショナリ（`session.state`）です。\n",
        " * そのセッション内の*複数の会話ターンにわたって*情報を保持します。\n",
        " * エージェントとツールはこの状態から読み取りや書き込みができ、詳細を記憶し、動作を適応させ、応答をパーソナライズすることができます。\n",
        " \n",
        " **エージェントが状態とやり取りする方法：**\n",
        " \n",
        " 1. **`ToolContext`（主要な方法）:** ツールは`ToolContext`オブジェクト（最後の引数として宣言されている場合、ADKによって自動的に提供される）を受け入れることができます。このオブジェクトは`tool_context.state`を通じてセッション状態への直接アクセスを提供し、ツールが実行*中に*設定を読み取ったり結果を保存したりできるようにします。\n",
        " 2. **`output_key`（エージェント応答の自動保存）:** `Agent`は`output_key=\"your_key\"`で構成できます。ADKはその後、ターンごとのエージェントの最終的なテキスト応答を`session.state[\"your_key\"]`に自動的に保存します。\n",
        " \n",
        " **このステップでは、天気ボットチームを以下のように強化します：**\n",
        " \n",
        " 1. 状態を分離して示すために**新しい**`InMemorySessionService`を使用します。\n",
        " 2. `temperature_unit`のユーザー設定でセッション状態を初期化します。\n",
        " 3. `ToolContext`を通じてこの設定を読み取り、出力形式（摂氏/華氏）を調整する状態対応バージョンの天気ツール（`get_weather_stateful`）を作成します。\n",
        " 4. ルートエージェントをこの状態対応ツールを使用するように更新し、`output_key`で構成して、最終的な天気レポートをセッション状態に自動的に保存するようにします。\n",
        " 5. 会話を実行して、初期状態がツールにどのように影響するか、手動での状態変更がその後の動作をどのように変更するか、そして`output_key`がエージェントの応答をどのように保持するかを観察します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsIjxunW1xeO"
      },
      "source": [
        " ---\n",
        " \n",
        " **1\\. 新しいセッションサービスと状態の初期化**\n",
        " \n",
        " 前のステップからの干渉なしに状態管理を明確に示すために、新しい`InMemorySessionService`をインスタンス化します。また、ユーザーの好みの温度単位を定義する初期状態でセッションを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wt21ea6ctFT5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 状態デモンストレーション用の新しいInMemorySessionServiceが作成されました。\n",
            "✅ ユーザー 'user_state_demo' のセッション 'session_state_demo_001' が作成されました。\n",
            "\n",
            "--- 初期セッション状態 ---\n",
            "{'user_preference_temperature_unit': 'Celsius'}\n"
          ]
        }
      ],
      "source": [
        "# @title 1. 新しいセッションサービスと状態の初期化\n",
        "\n",
        "# 必要なセッションコンポーネントをインポート\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "\n",
        "# この状態デモンストレーション用に新しいセッションサービスインスタンスを作成\n",
        "session_service_stateful = InMemorySessionService()\n",
        "print(\"✅ 状態デモンストレーション用の新しいInMemorySessionServiceが作成されました。\")\n",
        "\n",
        "# このチュートリアルのパート用に新しいセッションIDを定義\n",
        "SESSION_ID_STATEFUL = \"session_state_demo_001\"\n",
        "USER_ID_STATEFUL = \"user_state_demo\"\n",
        "\n",
        "# 初期状態データを定義 - ユーザーは最初に摂氏を好む\n",
        "# Define initial state data - user prefers Celsius initially\n",
        "initial_state = {\n",
        "    \"user_preference_temperature_unit\": \"Celsius\"\n",
        "}\n",
        "\n",
        "# 初期状態を提供してセッションを作成\n",
        "session_stateful = session_service_stateful.create_session(\n",
        "    app_name=APP_NAME, # 一貫したアプリ名を使用\n",
        "    user_id=USER_ID_STATEFUL,\n",
        "    session_id=SESSION_ID_STATEFUL,\n",
        "    state=initial_state # <<< 作成中に状態を初期化\n",
        ")\n",
        "print(f\"✅ ユーザー '{USER_ID_STATEFUL}' のセッション '{SESSION_ID_STATEFUL}' が作成されました。\")\n",
        "\n",
        "# 初期状態が正しく設定されたことを確認\n",
        "retrieved_session = session_service_stateful.get_session(app_name=APP_NAME,\n",
        "                                                            user_id=USER_ID_STATEFUL,\n",
        "                                                            session_id = SESSION_ID_STATEFUL)\n",
        "print(\"\\n--- 初期セッション状態 ---\")\n",
        "if retrieved_session:\n",
        "    print(retrieved_session.state)\n",
        "else:\n",
        "    print(\"エラー: セッションを取得できませんでした。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "652bNx3H16lJ"
      },
      "source": [
        " ---\n",
        " \n",
        " **2\\. 状態を認識する天気ツールの作成 (`get_weather_stateful`)**\n",
        " \n",
        " ここでは、天気ツールの新しいバージョンを作成します。その主な特徴は、`tool_context: ToolContext`を受け入れることで、`tool_context.state`にアクセスできることです。これにより、`user_preference_temperature_unit`を読み取り、それに応じて温度をフォーマットします。\n",
        " \n",
        " \n",
        " * **重要な概念: `ToolContext`** このオブジェクトは、ツールロジックがセッションのコンテキストと対話するための橋渡しとなり、状態変数の読み書きが可能になります。ADKは、ツール関数の最後のパラメータとして定義されていれば、自動的にこれを注入します。\n",
        " \n",
        " \n",
        " * **ベストプラクティス:** 状態から読み取る際は、`dictionary.get('key', default_value)`を使用して、キーがまだ存在しない場合に対応し、ツールがクラッシュしないようにします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zK11GeWftFRC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 状態を認識する 'get_weather_stateful' ツールが定義されました。\n"
          ]
        }
      ],
      "source": [
        "from google.adk.tools.tool_context import ToolContext\n",
        "\n",
        "def get_weather_stateful(city: str, tool_context: ToolContext) -> dict:\n",
        "    \"\"\"セッション状態に基づいて天気を取得し、温度単位を変換します。\"\"\"\n",
        "    print(f\"--- ツール: get_weather_stateful が {city} のために呼び出されました ---\")\n",
        "\n",
        "    # --- 状態から設定を読み取る ---\n",
        "    preferred_unit = tool_context.state.get(\"user_preference_temperature_unit\", \"Celsius\") # デフォルトは摂氏\n",
        "    print(f\"--- ツール: 状態 'user_preference_temperature_unit' を読み取り中: {preferred_unit} ---\")\n",
        "\n",
        "    city_normalized = city.lower().replace(\" \", \"\")\n",
        "\n",
        "    # モック天気データ（内部では常に摂氏で保存）\n",
        "    mock_weather_db = {\n",
        "        \"newyork\": {\"temp_c\": 25, \"condition\": \"sunny\"},\n",
        "        \"london\": {\"temp_c\": 15, \"condition\": \"cloudy\"},\n",
        "        \"tokyo\": {\"temp_c\": 18, \"condition\": \"light rain\"},\n",
        "        \"東京\": {\"temp_c\": 54, \"condition\": \"晴れ\"},\n",
        "    }\n",
        "\n",
        "    if city_normalized in mock_weather_db:\n",
        "        data = mock_weather_db[city_normalized]\n",
        "        temp_c = data[\"temp_c\"]\n",
        "        condition = data[\"condition\"]\n",
        "\n",
        "        # 状態の設定に基づいて温度をフォーマット\n",
        "        if preferred_unit == \"Fahrenheit\":\n",
        "            temp_value = (temp_c * 9/5) + 32 # 華氏に変換\n",
        "            temp_unit = \"°F\"\n",
        "        else: # デフォルトは摂氏\n",
        "            temp_value = temp_c\n",
        "            temp_unit = \"°C\"\n",
        "\n",
        "        report = f\"{city.capitalize()}の天気は{condition}で、気温は{temp_value:.0f}{temp_unit}です。\"\n",
        "        result = {\"status\": \"success\", \"report\": report}\n",
        "        print(f\"--- ツール: {preferred_unit}で天気レポートを生成しました。結果: {result} ---\")\n",
        "\n",
        "        # 状態に書き戻す例（このツールではオプション）\n",
        "        tool_context.state[\"last_city_checked_stateful\"] = city\n",
        "        print(f\"--- ツール: 状態 'last_city_checked_stateful' を更新: {city} ---\")\n",
        "\n",
        "        return result\n",
        "    else:\n",
        "        # 都市が見つからない場合の処理\n",
        "        error_msg = f\"申し訳ありませんが、'{city}'の天気情報はありません。\"\n",
        "        print(f\"--- ツール: 都市 '{city}' が見つかりません。 ---\")\n",
        "        return {\"status\": \"error\", \"error_message\": error_msg}\n",
        "\n",
        "print(\"✅ 状態を認識する 'get_weather_stateful' ツールが定義されました。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuQMolpG2Qkg"
      },
      "source": [
        " ---\n",
        " \n",
        " **3\\. サブエージェントの再定義とルートエージェントの更新**\n",
        " \n",
        " このステップが自己完結型で正しく構築されるように、まずステップ3と同様に`greeting_agent`と`farewell_agent`を再定義します。次に、新しいルートエージェント（`weather_agent_v4_stateful`）を定義します：\n",
        " \n",
        " * 新しい`get_weather_stateful`ツールを使用します。\n",
        " * 委任のためのあいさつと別れのサブエージェントを含みます。\n",
        " * **重要なポイント**として、`output_key=\"last_weather_report\"`を設定し、最終的な天気レポートをセッション状態に自動的に保存します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ox3-2hwTtFOK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ エージェント 'greeting_agent' が再定義されました。\n",
            "✅ エージェント 'farewell_agent' が再定義されました。\n",
            "✅ ルートエージェント 'weather_agent_v4_stateful' が状態認識ツールとoutput_keyを使用して作成されました。\n",
            "✅ 状態認識ルートエージェント 'weather_agent_v4_stateful' 用のランナーが状態認識セッションサービスを使用して作成されました。\n"
          ]
        }
      ],
      "source": [
        "# @title 3. サブエージェントの再定義とルートエージェントの更新（output_key付き）\n",
        "\n",
        "# 必要なインポート: Agent, LiteLlm, Runner\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.models.lite_llm import LiteLlm\n",
        "from google.adk.runners import Runner\n",
        "# ツール 'say_hello', 'say_goodbye' がステップ3から定義されていることを確認\n",
        "# モデル定数 MODEL_GPT_o3_MINI, MODEL_GEMINI_2_5_PRO などが定義されていることを確認\n",
        "\n",
        "# --- あいさつエージェントの再定義（ステップ3から） ---\n",
        "greeting_agent = None\n",
        "try:\n",
        "    greeting_agent = Agent(\n",
        "        model=LiteLlm(model=MODEL_GPT_o3_MINI),\n",
        "        name=\"greeting_agent\",\n",
        "        instruction=\"あなたはあいさつエージェントです。あなたの唯一のタスクは'say_hello'ツールを使用して友好的な挨拶を提供することです。それ以外は何もしないでください。\",\n",
        "        description=\"'say_hello'ツールを使用して簡単な挨拶を処理します。\",\n",
        "        tools=[say_hello],\n",
        "    )\n",
        "    print(f\"✅ エージェント '{greeting_agent.name}' が再定義されました。\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ あいさつエージェントを再定義できませんでした。エラー: {e}\")\n",
        "\n",
        "# --- 別れのエージェントの再定義（ステップ3から） ---\n",
        "farewell_agent = None\n",
        "try:\n",
        "    farewell_agent = Agent(\n",
        "        model=LiteLlm(model=MODEL_GPT_o3_MINI),\n",
        "        name=\"farewell_agent\",\n",
        "        instruction=\"あなたは別れのエージェントです。あなたの唯一のタスクは'say_goodbye'ツールを使用して丁寧な別れのメッセージを提供することです。他のアクションは実行しないでください。\",\n",
        "        description=\"'say_goodbye'ツールを使用して簡単な別れの挨拶を処理します。\",\n",
        "        tools=[say_goodbye],\n",
        "    )\n",
        "    print(f\"✅ エージェント '{farewell_agent.name}' が再定義されました。\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 別れのエージェントを再定義できませんでした。エラー: {e}\")\n",
        "\n",
        "# --- 更新されたルートエージェントの定義 ---\n",
        "root_agent_stateful = None\n",
        "runner_root_stateful = None # ランナーの初期化\n",
        "\n",
        "# ルートエージェントを作成する前に前提条件を確認\n",
        "if greeting_agent and farewell_agent and 'get_weather_stateful' in globals():\n",
        "\n",
        "    root_agent_model = LiteLlm(model=MODEL_GPT_o3_MINI) # オーケストレーションモデルの選択\n",
        "\n",
        "    root_agent_stateful = Agent(\n",
        "        name=\"weather_agent_v4_stateful\", # 新しいバージョン名\n",
        "        model=root_agent_model,\n",
        "        description=\"メインエージェント: 天気情報を提供（状態認識単位）、挨拶/別れを委任、レポートを状態に保存します。\",\n",
        "        instruction=\"あなたは主要な天気エージェントです。あなたの仕事は'get_weather_stateful'を使用して天気情報を提供することです。\"\n",
        "                    \"このツールは状態に保存されているユーザー設定に基づいて温度をフォーマットします。\"\n",
        "                    \"簡単な挨拶は'greeting_agent'に、別れは'farewell_agent'に委任してください。\"\n",
        "                    \"天気のリクエスト、挨拶、別れのみを処理してください。\",\n",
        "        tools=[get_weather_stateful], # 状態認識ツールを使用\n",
        "        sub_agents=[greeting_agent, farewell_agent], # サブエージェントを含める\n",
        "        output_key=\"last_weather_report\" # <<< エージェントの最終的な天気レスポンスを自動保存\n",
        "    )\n",
        "    print(f\"✅ ルートエージェント '{root_agent_stateful.name}' が状態認識ツールとoutput_keyを使用して作成されました。\")\n",
        "\n",
        "    # --- このルートエージェントと新しいセッションサービス用のランナーを作成 ---\n",
        "    runner_root_stateful = Runner(\n",
        "        agent=root_agent_stateful,\n",
        "        app_name=APP_NAME,\n",
        "        session_service=session_service_stateful # 新しい状態認識セッションサービスを使用\n",
        "    )\n",
        "    print(f\"✅ 状態認識ルートエージェント '{runner_root_stateful.agent.name}' 用のランナーが状態認識セッションサービスを使用して作成されました。\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ 状態認識ルートエージェントを作成できません。前提条件が不足しています。\")\n",
        "    if not greeting_agent: print(\" - greeting_agent の定義が不足しています。\")\n",
        "    if not farewell_agent: print(\" - farewell_agent の定義が不足しています。\")\n",
        "    if 'get_weather_stateful' not in globals(): print(\" - get_weather_stateful ツールが不足しています。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P394DfSb2aOw"
      },
      "source": [
        " ---\n",
        " \n",
        " **4\\. 状態フローの対話とテスト**\n",
        " \n",
        " ここでは、`runner_root_stateful`（状態を持つエージェントと`session_service_stateful`に関連付けられている）を使用して、状態の相互作用をテストするための会話を実行します。先ほど定義した`call_agent_async`関数を使用し、正しいランナー、ユーザーID（`USER_ID_STATEFUL`）、セッションID（`SESSION_ID_STATEFUL`）を渡すようにします。\n",
        " \n",
        " 会話の流れは次のとおりです：\n",
        " \n",
        " 1.  **天気の確認（ロンドン）：** `get_weather_stateful`ツールは、セクション1で初期化されたセッション状態から初期の「摂氏」設定を読み取ります。ルートエージェントの最終応答（摂氏での天気レポート）は、`output_key`設定を通じて`state['last_weather_report']`に保存されます。\n",
        " 2.  **手動での状態更新：** `InMemorySessionService`インスタンス（`session_service_stateful`）内に保存されている状態を*直接変更*します。\n",
        "     *   **なぜ直接変更するのか？** `session_service.get_session()`メソッドはセッションの*コピー*を返します。そのコピーを変更しても、後続のエージェント実行で使用される状態には影響しません。この`InMemorySessionService`を使用したテストシナリオでは、内部の`sessions`ディクショナリにアクセスして、`user_preference_temperature_unit`の*実際の*保存値を「華氏」に変更します。*注意：実際のアプリケーションでは、状態の変更は通常、直接手動更新ではなく、ツールやエージェントのロジックが`EventActions(state_delta=...)`を返すことによってトリガーされます。*\n",
        " 3.  **再度天気を確認（ニューヨーク）：** `get_weather_stateful`ツールは、状態から更新された「華氏」設定を読み取り、それに応じて温度を変換します。ルートエージェントの*新しい*応答（華氏での天気）は、`output_key`により`state['last_weather_report']`の以前の値を上書きします。\n",
        " 4.  **エージェントに挨拶：** 状態を持つ操作と並行して、`greeting_agent`への委任が正しく機能することを確認します。この対話は、この特定のシーケンスで`output_key`によって保存される*最後の*応答になります。\n",
        " 5.  **最終状態の検査：** 会話の後、セッションを最後にもう一度取得し（コピーを取得）、その状態を出力して`user_preference_temperature_unit`が確かに「華氏」になっていることを確認し、`output_key`によって保存された最終値（この実行では挨拶）を観察し、ツールによって書き込まれた`last_city_checked_stateful`の値を確認します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WYZfRCp0tFLT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 状態テスト: 温度単位変換とoutput_key ---\n",
            "--- ターン1: ロンドンの天気をリクエスト（摂氏を期待）---\n",
            "\n",
            ">>> ユーザークエリ: ロンドンの天気はどうですか？\n",
            "--- ツール: get_weather_stateful が London のために呼び出されました ---\n",
            "--- ツール: 状態 'user_preference_temperature_unit' を読み取り中: Celsius ---\n",
            "--- ツール: Celsiusで天気レポートを生成しました。結果: {'status': 'success', 'report': 'Londonの天気はcloudyで、気温は15°Cです。'} ---\n",
            "--- ツール: 状態 'last_city_checked_stateful' を更新: London ---\n",
            "<<< エージェント応答: Londonの天気はcloudyで、気温は15°Cです。\n",
            "\n",
            "--- 状態を手動で更新: 単位を華氏に設定 ---\n",
            "--- 保存されたセッション状態が更新されました。現在の 'user_preference_temperature_unit': Fahrenheit ---\n",
            "\n",
            "--- ターン2: ニューヨークの天気をリクエスト（華氏を期待）---\n",
            "\n",
            ">>> ユーザークエリ: ニューヨークの天気を教えてください。\n",
            "--- ツール: get_weather_stateful が New York のために呼び出されました ---\n",
            "--- ツール: 状態 'user_preference_temperature_unit' を読み取り中: Fahrenheit ---\n",
            "--- ツール: Fahrenheitで天気レポートを生成しました。結果: {'status': 'success', 'report': 'New yorkの天気はsunnyで、気温は77°Fです。'} ---\n",
            "--- ツール: 状態 'last_city_checked_stateful' を更新: New York ---\n",
            "<<< エージェント応答: New Yorkの天気はsunnyで、気温は77°Fです。\n",
            "\n",
            "--- ターン3: 挨拶を送信 ---\n",
            "\n",
            ">>> ユーザークエリ: こんにちは！\n",
            "--- ツール: say_hello が name: there で呼び出されました ---\n",
            "<<< エージェント応答: こんにちは！お元気ですか？\n",
            "\n",
            "--- 最終セッション状態の検査 ---\n",
            "最終設定: Fahrenheit\n",
            "最終天気レポート（output_keyから）: こんにちは！お元気ですか？\n",
            "最終確認都市（ツールによる）: New York\n"
          ]
        }
      ],
      "source": [
        "# @title 4. 状態フローとoutput_keyをテストするための対話\n",
        "\n",
        "# 前のセルから状態を持つランナー（runner_root_stateful）が利用可能であることを確認\n",
        "# call_agent_async、USER_ID_STATEFUL、SESSION_ID_STATEFUL、APP_NAMEが定義されていることを確認\n",
        "\n",
        "if 'runner_root_stateful' in globals() and runner_root_stateful:\n",
        "    async def run_stateful_conversation():\n",
        "        print(\"\\n--- 状態テスト: 温度単位変換とoutput_key ---\")\n",
        "\n",
        "        # 1. 天気を確認（初期状態: 摂氏）\n",
        "        print(\"--- ターン1: ロンドンの天気をリクエスト（摂氏を期待）---\")\n",
        "        await call_agent_async(query= \"ロンドンの天気はどうですか？\",\n",
        "                                runner=runner_root_stateful,\n",
        "                                user_id=USER_ID_STATEFUL,\n",
        "                                session_id=SESSION_ID_STATEFUL\n",
        "                            )\n",
        "\n",
        "        # 2. 手動で状態の設定を華氏に更新 - ストレージを直接変更\n",
        "        print(\"\\n--- 状態を手動で更新: 単位を華氏に設定 ---\")\n",
        "        try:\n",
        "            # 内部ストレージに直接アクセス - これはテスト用のInMemorySessionServiceに特有のもの\n",
        "            stored_session = session_service_stateful.sessions[APP_NAME][USER_ID_STATEFUL][SESSION_ID_STATEFUL]\n",
        "            stored_session.state[\"user_preference_temperature_unit\"] = \"Fahrenheit\"\n",
        "            # オプション: ロジックがタイムスタンプに依存する場合は、タイムスタンプも更新するとよいでしょう\n",
        "            # import time\n",
        "            # stored_session.last_update_time = time.time()\n",
        "            print(f\"--- 保存されたセッション状態が更新されました。現在の 'user_preference_temperature_unit': {stored_session.state['user_preference_temperature_unit']} ---\")\n",
        "        except KeyError:\n",
        "            print(f\"--- エラー: 状態を更新するために、アプリ '{APP_NAME}' のユーザー '{USER_ID_STATEFUL}' のセッション '{SESSION_ID_STATEFUL}' を内部ストレージから取得できませんでした。IDを確認し、セッションが作成されているか確認してください。 ---\")\n",
        "        except Exception as e:\n",
        "            print(f\"--- 内部セッション状態の更新エラー: {e} ---\")\n",
        "\n",
        "        # 3. 再度天気を確認（ツールは華氏を使用するはず）\n",
        "        # これはoutput_keyを通じて'last_weather_report'も更新します\n",
        "        print(\"\\n--- ターン2: ニューヨークの天気をリクエスト（華氏を期待）---\")\n",
        "        await call_agent_async(query= \"ニューヨークの天気を教えてください。\",\n",
        "                                runner=runner_root_stateful,\n",
        "                                user_id=USER_ID_STATEFUL,\n",
        "                                session_id=SESSION_ID_STATEFUL\n",
        "                            )\n",
        "\n",
        "        # 4. 基本的な委任をテスト（まだ機能するはず）\n",
        "        # これは'last_weather_report'を再度更新し、NYの天気レポートを上書きします\n",
        "        print(\"\\n--- ターン3: 挨拶を送信 ---\")\n",
        "        await call_agent_async(query= \"こんにちは！\",\n",
        "                                runner=runner_root_stateful,\n",
        "                                user_id=USER_ID_STATEFUL,\n",
        "                                session_id=SESSION_ID_STATEFUL\n",
        "                                )\n",
        "\n",
        "    # 会話を実行\n",
        "    await run_stateful_conversation()\n",
        "\n",
        "    # 会話後の最終セッション状態を検査\n",
        "    print(\"\\n--- 最終セッション状態の検査 ---\")\n",
        "    final_session = session_service_stateful.get_session(app_name=APP_NAME,\n",
        "                                                        user_id= USER_ID_STATEFUL,\n",
        "                                                        session_id=SESSION_ID_STATEFUL)\n",
        "    if final_session: \n",
        "        print(f\"最終設定: {final_session.state.get('user_preference_temperature_unit')}\")\n",
        "        print(f\"最終天気レポート（output_keyから）: {final_session.state.get('last_weather_report')}\")\n",
        "        print(f\"最終確認都市（ツールによる）: {final_session.state.get('last_city_checked_stateful')}\")\n",
        "        # 詳細表示のために完全な状態を表示\n",
        "        # print(f\"完全な状態: {final_session.state}\")\n",
        "    else:\n",
        "        print(\"\\n❌ エラー: 最終セッション状態を取得できませんでした。\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n⚠️ 状態テスト会話をスキップします。状態を持つルートエージェントランナー（'runner_root_stateful'）が利用できません。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqiG4SAX2l8C"
      },
      "source": [
        " ---\n",
        " \n",
        " 会話の流れと最終セッション状態の出力を確認することで、以下のことが確認できます：\n",
        " \n",
        " *   **状態の読み取り：** 天気ツール（`get_weather_stateful`）は状態から`user_preference_temperature_unit`を正しく読み取り、最初はロンドンの天気を「摂氏」で表示しました。\n",
        " *   **状態の更新：** 直接的な変更により、保存された設定が「華氏」に正常に変更されました。\n",
        " *   **状態の読み取り（更新後）：** ツールはニューヨークの天気を尋ねられたとき、「華氏」を読み取り、変換を実行しました。\n",
        " *   **ツールによる状態の書き込み：** ツールは`tool_context.state`を通じて`last_city_checked_stateful`（2回目の天気確認後の「ニューヨーク」）を状態に正常に書き込みました。\n",
        " *   **委任：** 状態が変更された後でも、「こんにちは！」に対する`greeting_agent`への委任は正常に機能しました。\n",
        " *   **`output_key`：** `output_key=\"last_weather_report\"`は、ルートエージェントが最終的に応答した*各ターン*の*最終*応答を正常に保存しました。このシーケンスでは、最後の応答は挨拶（「こんにちは！」）だったため、状態キー内の天気レポートが上書きされました。\n",
        " *   **最終状態：** 最終確認により、設定が「華氏」として維持されていることが確認されました。\n",
        " \n",
        " これで、`ToolContext`を使用してエージェントの動作をパーソナライズするためのセッション状態の統合、`InMemorySessionService`をテストするための状態の手動操作、そして`output_key`がエージェントの最後の応答を状態に保存するためのシンプルなメカニズムを提供する方法を確認できました。この状態管理の基本的な理解は、次のステップでコールバックを使用して安全性ガードレールを実装する際に重要となります。\n",
        " \n",
        " ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwTcmu0oaEiI"
      },
      "source": [
        "# ## ステップ5: 安全性の追加 - `before_model_callback`を使用した入力ガードレール\n",
        "\n",
        "私たちのエージェントチームは、設定を記憶しツールを効果的に使用するなど、より高機能になってきています。しかし、実際のシナリオでは、潜在的に問題のあるリクエストがコアの大規模言語モデル（LLM）に到達する*前に*、エージェントの動作を制御するための安全メカニズムが必要になることがよくあります。\n",
        "\n",
        "ADKは**コールバック**を提供しています - エージェントの実行ライフサイクルの特定のポイントにフックできる関数です。特に`before_model_callback`は入力の安全性に非常に役立ちます。\n",
        "\n",
        "**`before_model_callback`とは？**\n",
        "\n",
        "* エージェントがコンパイルされたリクエスト（会話履歴、指示、最新のユーザーメッセージを含む）を基盤となるLLMに送信する*直前に*、ADKが実行するあなたが定義するPython関数です。\n",
        "* **目的:** リクエストを検査し、必要に応じて変更したり、事前定義されたルールに基づいて完全にブロックしたりします。\n",
        "\n",
        "**一般的なユースケース:**\n",
        "\n",
        "* **入力の検証/フィルタリング:** ユーザー入力が基準を満たしているか、または許可されていないコンテンツ（PIIやキーワードなど）を含んでいないかを確認します。\n",
        "* **ガードレール:** 有害、トピック外、またはポリシー違反のリクエストがLLMによって処理されるのを防ぎます。\n",
        "* **動的プロンプト修正:** 送信直前にLLMリクエストコンテキストにタイムリーな情報（セッション状態からなど）を追加します。\n",
        "\n",
        "**仕組み:**\n",
        "\n",
        "1. `callback_context: CallbackContext`と`llm_request: LlmRequest`を受け入れる関数を定義します。\n",
        "   * `callback_context`: エージェント情報、セッション状態（`callback_context.state`）などへのアクセスを提供します。\n",
        "   * `llm_request`: LLM向けの完全なペイロード（`contents`、`config`）を含みます。\n",
        "2. 関数内で:\n",
        "   * **検査:** `llm_request.contents`（特に最後のユーザーメッセージ）を調べます。\n",
        "   * **修正（注意して使用）:** `llm_request`の一部を変更*できます*。\n",
        "   * **ブロック（ガードレール）:** `LlmResponse`オブジェクトを返します。ADKはこの応答をすぐに送り返し、そのターンのLLM呼び出しを*スキップ*します。\n",
        "   * **許可:** `None`を返します。ADKは（潜在的に修正された）リクエストでLLMを呼び出します。\n",
        "\n",
        "**このステップでは:**\n",
        "\n",
        "1. ユーザーの入力に特定のキーワード（「BLOCK」）がないかチェックする`before_model_callback`関数（`block_keyword_guardrail`）を定義します。\n",
        "2. ステップ4の状態を持つルートエージェント（`weather_agent_v4_stateful`）を更新して、このコールバックを使用します。\n",
        "3. この更新されたエージェントに関連付けられた新しいランナーを作成しますが、状態の継続性を維持するために*同じ状態を持つセッションサービス*を使用します。\n",
        "4. 通常のリクエストとキーワードを含むリクエストの両方を送信して、ガードレールをテストします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7m6zhMv4Zss"
      },
      "source": [
        " ---\n",
        " \n",
        " **1\\. ガードレールコールバック関数の定義**\n",
        " \n",
        " この関数は`llm_request`コンテンツ内の最後のユーザーメッセージを検査します。「BLOCK」（大文字小文字を区別しない）が見つかった場合、フローをブロックするために`LlmResponse`を構築して返します。それ以外の場合は`None`を返します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZay2mbHaHSk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ block_keyword_guardrail関数が定義されました。\n"
          ]
        }
      ],
      "source": [
        "# @title 1. before_model_callback ガードレールの定義\n",
        "\n",
        "# 必要なインポートを確保\n",
        "from google.adk.agents.callback_context import CallbackContext\n",
        "from google.adk.models.llm_request import LlmRequest\n",
        "from google.adk.models.llm_response import LlmResponse\n",
        "from google.genai import types # レスポンスコンテンツの作成用\n",
        "from typing import Optional\n",
        "\n",
        "def block_keyword_guardrail(\n",
        "    callback_context: CallbackContext, llm_request: LlmRequest\n",
        ") -> Optional[LlmResponse]:\n",
        "    \"\"\"\n",
        "    最新のユーザーメッセージに「BLOCK」が含まれているか検査します。見つかった場合、\n",
        "    LLM呼び出しをブロックし、事前定義されたLlmResponseを返します。それ以外の場合はNoneを返して処理を続行します。\n",
        "    \"\"\"\n",
        "    agent_name = callback_context.agent_name # インターセプトされているエージェントの名前を取得\n",
        "    print(f\"--- コールバック: block_keyword_guardrail が実行中 エージェント: {agent_name} ---\")\n",
        "\n",
        "    # リクエスト履歴から最新のユーザーメッセージのテキストを抽出\n",
        "    last_user_message_text = \"\"\n",
        "    if llm_request.contents:\n",
        "        # ロールが「user」の最新のメッセージを検索\n",
        "        for content in reversed(llm_request.contents):\n",
        "            if content.role == 'user' and content.parts:\n",
        "                # 簡略化のため、テキストは最初のパートにあると仮定\n",
        "                if content.parts[0].text:\n",
        "                    last_user_message_text = content.parts[0].text\n",
        "                    break # 最後のユーザーメッセージテキストを見つけた\n",
        "\n",
        "    print(f\"--- コールバック: 最後のユーザーメッセージを検査中: '{last_user_message_text[:100]}...' ---\") # 最初の100文字をログに記録\n",
        "\n",
        "    # --- ガードレールロジック ---\n",
        "    keyword_to_block = \"BLOCK\"\n",
        "    if keyword_to_block in last_user_message_text.upper(): # 大文字小文字を区別しないチェック\n",
        "        print(f\"--- コールバック: '{keyword_to_block}'が見つかりました。LLM呼び出しをブロックします！ ---\")\n",
        "        # オプションで、ブロックイベントを記録するためにステートにフラグを設定\n",
        "        callback_context.state[\"guardrail_block_keyword_triggered\"] = True\n",
        "        print(f\"--- コールバック: ステート 'guardrail_block_keyword_triggered': True を設定しました ---\")\n",
        "\n",
        "        # フローを停止し、代わりにこれを送信するためのLlmResponseを構築して返す\n",
        "        return LlmResponse(\n",
        "            content=types.Content(\n",
        "                role=\"model\", # エージェントの視点からの応答を模倣\n",
        "                parts=[types.Part(text=f\"このリクエストには禁止キーワード '{keyword_to_block}' が含まれているため、処理できません。\")],\n",
        "            )\n",
        "            # 注：必要に応じてここにerror_messageフィールドを設定することもできます\n",
        "        )\n",
        "    else:\n",
        "        # キーワードが見つからなかった場合、リクエストをLLMに進めることを許可\n",
        "        print(f\"--- コールバック: キーワードが見つかりませんでした。{agent_name}のLLM呼び出しを許可します。 ---\")\n",
        "        return None # Noneを返すことで、ADKに通常通り続行するよう指示\n",
        "\n",
        "print(\"✅ block_keyword_guardrail関数が定義されました。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giawLd9VaI7G"
      },
      "source": [
        " ---\n",
        " \n",
        " **2\\. コールバックを使用するためのルートエージェントの更新**\n",
        " \n",
        " ルートエージェントを再定義し、`before_model_callback`パラメータを追加して、新しいガードレール関数を指定します。わかりやすくするために、新しいバージョン名を付けます。\n",
        " \n",
        "\n",
        " *重要:* サブエージェント（`greeting_agent`、`farewell_agent`）とステートフルツール（`get_weather_stateful`）が前のステップからすでに利用可能でない場合は、このコンテキスト内で再定義する必要があります。これにより、ルートエージェントの定義がすべてのコンポーネントにアクセスできるようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'LiteLlm' object has no attribute 'complete'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m llm = LiteLlm(model=MODEL_GPT_o3_MINI)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# APIリクエストを送信してレスポンスを取得\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# LiteLlmではcomplete()メソッドを使用\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplete\u001b[49m(\n\u001b[32m     10\u001b[39m     prompt=\u001b[33m\"\u001b[39m\u001b[33mこんにちは、今日の天気を教えてください。\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     temperature=\u001b[32m0.7\u001b[39m,\n\u001b[32m     12\u001b[39m     max_tokens=\u001b[32m100\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAPIレスポンス:\u001b[39m\u001b[33m\"\u001b[39m, response.choices[\u001b[32m0\u001b[39m].message.content)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/progressive_weather_bot/python3.12/lib/python3.12/site-packages/pydantic/main.py:994\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    991\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    993\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m994\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: 'LiteLlm' object has no attribute 'complete'"
          ]
        }
      ],
      "source": [
        "# LiteLlmを使ったシンプルな対話\n",
        "# LiteLlmモデルを初期化\n",
        "# LiteLlmはcompletion()メソッドを持っていないため、\n",
        "# 正しいメソッドを使用する必要があります\n",
        "llm = LiteLlm(model=MODEL_GPT_o3_MINI)\n",
        "\n",
        "# APIリクエストを送信してレスポンスを取得\n",
        "# LiteLlmではcomplete()メソッドを使用\n",
        "response = llm.complete(\n",
        "    prompt=\"こんにちは、今日の天気を教えてください。\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=100\n",
        ")\n",
        "print(\"APIレスポンス:\", response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IRoMmJ9V_cuH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ 挨拶エージェントを再定義できませんでした。モデル/APIキー(openai/o3-mini-2025-01-31)を確認してください。エラー: name 'say_hello' is not defined\n",
            "❌ 別れのエージェントを再定義できませんでした。モデル/APIキー(openai/o3-mini-2025-01-31)を確認してください。エラー: name 'say_goodbye' is not defined\n",
            "❌ モデルガードレール付きのルートエージェントを作成できません。前提条件の1つ以上が欠落しているか、初期化に失敗しました：\n",
            "   - 挨拶エージェント\n",
            "   - 別れのエージェント\n",
            "   - 'get_weather_stateful' ツール\n"
          ]
        }
      ],
      "source": [
        "# @title 2. コールバック付きルートエージェントの更新\n",
        "\n",
        "\n",
        "# --- サブエージェントの再定義（このコンテキストで存在することを確認） ---\n",
        "greeting_agent = None\n",
        "try:\n",
        "    # 定義済みのモデル定数を使用\n",
        "    greeting_agent = Agent(\n",
        "        model=LiteLlm(model=MODEL_GPT_o3_MINI),\n",
        "        name=\"greeting_agent\", # 一貫性のために元の名前を維持\n",
        "        instruction=\"あなたは挨拶エージェントです。あなたの唯一のタスクは「say_hello」ツールを使用して友好的な挨拶を提供することです。それ以外は何もしないでください。\",\n",
        "        description=\"「say_hello」ツールを使用して簡単な挨拶を処理します。\",\n",
        "        tools=[say_hello],\n",
        "    )\n",
        "    print(f\"✅ サブエージェント '{greeting_agent.name}' が再定義されました。\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 挨拶エージェントを再定義できませんでした。モデル/APIキー({MODEL_GPT_o3_MINI})を確認してください。エラー: {e}\")\n",
        "\n",
        "farewell_agent = None\n",
        "try:\n",
        "    # 定義済みのモデル定数を使用\n",
        "    farewell_agent = Agent(\n",
        "        model=LiteLlm(model=MODEL_GPT_o3_MINI),\n",
        "        name=\"farewell_agent\", # 元の名前を維持\n",
        "        instruction=\"あなたは別れのエージェントです。あなたの唯一のタスクは「say_goodbye」ツールを使用して丁寧な別れのメッセージを提供することです。他のアクションは実行しないでください。\",\n",
        "        description=\"「say_goodbye」ツールを使用して簡単な別れの挨拶を処理します。\",\n",
        "        tools=[say_goodbye],\n",
        "    )\n",
        "    print(f\"✅ サブエージェント '{farewell_agent.name}' が再定義されました。\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 別れのエージェントを再定義できませんでした。モデル/APIキー({MODEL_GPT_o3_MINI})を確認してください。エラー: {e}\")\n",
        "\n",
        "\n",
        "# --- コールバック付きのルートエージェントを定義 ---\n",
        "root_agent_model_guardrail = None\n",
        "runner_root_model_guardrail = None\n",
        "\n",
        "# 進める前にすべてのコンポーネントを確認\n",
        "if greeting_agent and farewell_agent and 'get_weather_stateful' in globals() and 'block_keyword_guardrail' in globals():\n",
        "\n",
        "    # MODEL_GEMINI_2_5_PROのような定義済みモデル定数を使用\n",
        "    root_agent_model = LiteLlm(model=MODEL_GPT_o3_MINI)\n",
        "\n",
        "    root_agent_model_guardrail = Agent(\n",
        "        name=\"weather_agent_v5_model_guardrail\", # 明確にするための新バージョン名\n",
        "        model=root_agent_model,\n",
        "        description=\"メインエージェント：天気を処理し、挨拶/別れを委任し、入力キーワードガードレールを含みます。\",\n",
        "        instruction=\"あなたは主要な天気エージェントです。「get_weather_stateful」を使用して天気情報を提供します。\"\n",
        "                    \"簡単な挨拶は「greeting_agent」に、別れは「farewell_agent」に委任します。\"\n",
        "                    \"天気のリクエスト、挨拶、別れのみを処理してください。\",\n",
        "        tools=[get_weather],\n",
        "        sub_agents=[greeting_agent, farewell_agent], # 再定義されたサブエージェントを参照\n",
        "        output_key=\"last_weather_report\", # ステップ4からoutput_keyを維持\n",
        "        before_model_callback=block_keyword_guardrail # <<< ガードレールコールバックを割り当て\n",
        "    )\n",
        "    print(f\"✅ ルートエージェント '{root_agent_model_guardrail.name}' がbefore_model_callbackで作成されました。\")\n",
        "\n",
        "    # --- このエージェント用のランナーを作成、同じステートフルセッションサービスを使用 ---\n",
        "    # ステップ4からsession_service_statefulが存在することを確認\n",
        "    if 'session_service_stateful' in globals():\n",
        "        runner_root_model_guardrail = Runner(\n",
        "            agent=root_agent_model_guardrail,\n",
        "            app_name=APP_NAME, # 一貫したAPP_NAMEを使用\n",
        "            session_service=session_service_stateful # <<< ステップ4からのサービスを使用\n",
        "        )\n",
        "        print(f\"✅ ガードレールエージェント '{runner_root_model_guardrail.agent.name}' 用のランナーが作成され、ステートフルセッションサービスを使用しています。\")\n",
        "    else:\n",
        "        print(\"❌ ランナーを作成できません。ステップ4からの 'session_service_stateful' がありません。\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ モデルガードレール付きのルートエージェントを作成できません。前提条件の1つ以上が欠落しているか、初期化に失敗しました：\")\n",
        "    if not greeting_agent: print(\"   - 挨拶エージェント\")\n",
        "    if not farewell_agent: print(\"   - 別れのエージェント\")\n",
        "    if 'get_weather_stateful' not in globals(): print(\"   - 'get_weather_stateful' ツール\")\n",
        "    if 'block_keyword_guardrail' not in globals(): print(\"   - 'block_keyword_guardrail' コールバック\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2EW2LSS4wnz"
      },
      "source": [
        "---\n",
        "\n",
        "**3\\. Interact to Test the Guardrail**\n",
        "\n",
        "Let's test the guardrail's behavior. We'll use the *same session* (`SESSION_ID_STATEFUL`) as in Step 4 to show that state persists across these changes.\n",
        "\n",
        "1. Send a normal weather request (should pass the guardrail and execute).  \n",
        "2. Send a request containing \"BLOCK\" (should be intercepted by the callback).  \n",
        "3. Send a greeting (should pass the root agent's guardrail, be delegated, and execute normally)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EnMiXX8aO9n"
      },
      "outputs": [],
      "source": [
        "# @title 3. Interact to Test the Model Input Guardrail\n",
        "\n",
        "# Ensure the runner for the guardrail agent is available\n",
        "if runner_root_model_guardrail:\n",
        "  async def run_guardrail_test_conversation():\n",
        "      print(\"\\n--- Testing Model Input Guardrail ---\")\n",
        "\n",
        "      # Use the runner for the agent with the callback and the existing stateful session ID\n",
        "      interaction_func = lambda query: call_agent_async(query,\n",
        "      runner_root_model_guardrail, USER_ID_STATEFUL, SESSION_ID_STATEFUL # <-- Pass correct IDs\n",
        "  )\n",
        "      # 1. Normal request (Callback allows, should use Fahrenheit from Step 4 state change)\n",
        "      await interaction_func(\"What is the weather in London?\")\n",
        "\n",
        "      # 2. Request containing the blocked keyword\n",
        "      await interaction_func(\"BLOCK the request for weather in Tokyo\")\n",
        "\n",
        "      # 3. Normal greeting (Callback allows root agent, delegation happens)\n",
        "      await interaction_func(\"Hello again\")\n",
        "\n",
        "\n",
        "  # Execute the conversation\n",
        "  await run_guardrail_test_conversation()\n",
        "\n",
        "  # Optional: Check state for the trigger flag set by the callback\n",
        "  final_session = session_service_stateful.get_session(app_name=APP_NAME,\n",
        "                                                       user_id=USER_ID_STATEFUL,\n",
        "                                                       session_id=SESSION_ID_STATEFUL)\n",
        "  if final_session:\n",
        "      print(\"\\n--- Final Session State (After Guardrail Test) ---\")\n",
        "      print(f\"Guardrail Triggered Flag: {final_session.state.get('guardrail_block_keyword_triggered')}\")\n",
        "      print(f\"Last Weather Report: {final_session.state.get('last_weather_report')}\") # Should be London weather\n",
        "      print(f\"Temperature Unit: {final_session.state.get('user_preference_temperature_unit')}\") # Should be Fahrenheit\n",
        "  else:\n",
        "      print(\"\\n❌ Error: Could not retrieve final session state.\")\n",
        "\n",
        "else:\n",
        "  print(\"\\n⚠️ Skipping model guardrail test. Runner ('runner_root_model_guardrail') is not available.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5D0KaW-aQ8z"
      },
      "source": [
        "---\n",
        "\n",
        "Observe the execution flow:\n",
        "\n",
        "1. **London Weather:** The callback runs for `weather_agent_v5_model_guardrail`, inspects the message, prints \"Keyword not found. Allowing LLM call.\", and returns `None`. The agent proceeds, calls the `get_weather_stateful` tool (which uses the \"Fahrenheit\" preference from Step 4's state change), and returns the weather. This response updates `last_weather_report` via `output_key`.  \n",
        "2. **BLOCK Request:** The callback runs again for `weather_agent_v5_model_guardrail`, inspects the message, finds \"BLOCK\", prints \"Blocking LLM call\\!\", sets the state flag, and returns the predefined `LlmResponse`. The agent's underlying LLM is *never called* for this turn. The user sees the callback's blocking message.  \n",
        "3. **Hello Again:** The callback runs for `weather_agent_v5_model_guardrail`, allows the request. The root agent then delegates to `greeting_agent`. *Note: The `before_model_callback` defined on the root agent does NOT automatically apply to sub-agents.* The `greeting_agent` proceeds normally, calls its `say_hello` tool, and returns the greeting.\n",
        "\n",
        "You have successfully implemented an input safety layer\\! The `before_model_callback` provides a powerful mechanism to enforce rules and control agent behavior *before* expensive or potentially risky LLM calls are made. Next, we'll apply a similar concept to add guardrails around tool usage itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnH5C0IRaqet"
      },
      "source": [
        "## Step 6: Adding Safety \\- Tool Argument Guardrail (`before_tool_callback`)\n",
        "\n",
        "In Step 5, we added a guardrail to inspect and potentially block user input *before* it reached the LLM. Now, we'll add another layer of control *after* the LLM has decided to use a tool but *before* that tool actually executes. This is useful for validating the *arguments* the LLM wants to pass to the tool.\n",
        "\n",
        "ADK provides the `before_tool_callback` for this precise purpose.\n",
        "\n",
        "**What is `before_tool_callback`?**\n",
        "\n",
        "* It's a Python function executed just *before* a specific tool function runs, after the LLM has requested its use and decided on the arguments.  \n",
        "* **Purpose:** Validate tool arguments, prevent tool execution based on specific inputs, modify arguments dynamically, or enforce resource usage policies.\n",
        "\n",
        "**Common Use Cases:**\n",
        "\n",
        "* **Argument Validation:** Check if arguments provided by the LLM are valid, within allowed ranges, or conform to expected formats.  \n",
        "* **Resource Protection:** Prevent tools from being called with inputs that might be costly, access restricted data, or cause unwanted side effects (e.g., blocking API calls for certain parameters).  \n",
        "* **Dynamic Argument Modification:** Adjust arguments based on session state or other contextual information before the tool runs.\n",
        "\n",
        "**How it Works:**\n",
        "\n",
        "1. Define a function accepting `tool: BaseTool`, `args: Dict[str, Any]`, and `tool_context: ToolContext`.  \n",
        "   * `tool`: The tool object about to be called (inspect `tool.name`).  \n",
        "   * `args`: The dictionary of arguments the LLM generated for the tool.  \n",
        "   * `tool_context`: Provides access to session state (`tool_context.state`), agent info, etc.  \n",
        "2. Inside the function:  \n",
        "   * **Inspect:** Examine the `tool.name` and the `args` dictionary.  \n",
        "   * **Modify:** Change values within the `args` dictionary *directly*. If you return `None`, the tool runs with these modified args.  \n",
        "   * **Block/Override (Guardrail):** Return a **dictionary**. ADK treats this dictionary as the *result* of the tool call, completely *skipping* the execution of the original tool function. The dictionary should ideally match the expected return format of the tool it's blocking.  \n",
        "   * **Allow:** Return `None`. ADK proceeds to execute the actual tool function with the (potentially modified) arguments.\n",
        "\n",
        "**In this step, we will:**\n",
        "\n",
        "1. Define a `before_tool_callback` function (`block_paris_tool_guardrail`) that specifically checks if the `get_weather_stateful` tool is called with the city \"Paris\".  \n",
        "2. If \"Paris\" is detected, the callback will block the tool and return a custom error dictionary.  \n",
        "3. Update our root agent (`weather_agent_v6_tool_guardrail`) to include *both* the `before_model_callback` and this new `before_tool_callback`.  \n",
        "4. Create a new runner for this agent, using the same stateful session service.  \n",
        "5. Test the flow by requesting weather for allowed cities and the blocked city (\"Paris\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5myniS17Q5q"
      },
      "source": [
        "---\n",
        "\n",
        "**1\\. Define the Tool Guardrail Callback Function**\n",
        "\n",
        "This function targets the `get_weather_stateful` tool. It checks the `city` argument. If it's \"Paris\", it returns an error dictionary that looks like the tool's own error response. Otherwise, it allows the tool to run by returning `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4wOLl6aastz"
      },
      "outputs": [],
      "source": [
        "# @title 1. Define the before_tool_callback Guardrail\n",
        "\n",
        "# Ensure necessary imports are available\n",
        "from google.adk.tools.base_tool import BaseTool\n",
        "from google.adk.tools.tool_context import ToolContext\n",
        "from typing import Optional, Dict, Any # For type hints\n",
        "\n",
        "def block_paris_tool_guardrail(\n",
        "    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext\n",
        ") -> Optional[Dict]:\n",
        "    \"\"\"\n",
        "    Checks if 'get_weather_stateful' is called for 'Paris'.\n",
        "    If so, blocks the tool execution and returns a specific error dictionary.\n",
        "    Otherwise, allows the tool call to proceed by returning None.\n",
        "    \"\"\"\n",
        "    tool_name = tool.name\n",
        "    agent_name = tool_context.agent_name # Agent attempting the tool call\n",
        "    print(f\"--- Callback: block_paris_tool_guardrail running for tool '{tool_name}' in agent '{agent_name}' ---\")\n",
        "    print(f\"--- Callback: Inspecting args: {args} ---\")\n",
        "\n",
        "    # --- Guardrail Logic ---\n",
        "    target_tool_name = \"get_weather_stateful\" # Match the function name used by FunctionTool\n",
        "    blocked_city = \"paris\"\n",
        "\n",
        "    # Check if it's the correct tool and the city argument matches the blocked city\n",
        "    if tool_name == target_tool_name:\n",
        "        city_argument = args.get(\"city\", \"\") # Safely get the 'city' argument\n",
        "        if city_argument and city_argument.lower() == blocked_city:\n",
        "            print(f\"--- Callback: Detected blocked city '{city_argument}'. Blocking tool execution! ---\")\n",
        "            # Optionally update state\n",
        "            tool_context.state[\"guardrail_tool_block_triggered\"] = True\n",
        "            print(f\"--- Callback: Set state 'guardrail_tool_block_triggered': True ---\")\n",
        "\n",
        "            # Return a dictionary matching the tool's expected output format for errors\n",
        "            # This dictionary becomes the tool's result, skipping the actual tool run.\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"error_message\": f\"Policy restriction: Weather checks for '{city_argument.capitalize()}' are currently disabled by a tool guardrail.\"\n",
        "            }\n",
        "        else:\n",
        "             print(f\"--- Callback: City '{city_argument}' is allowed for tool '{tool_name}'. ---\")\n",
        "    else:\n",
        "        print(f\"--- Callback: Tool '{tool_name}' is not the target tool. Allowing. ---\")\n",
        "\n",
        "\n",
        "    # If the checks above didn't return a dictionary, allow the tool to execute\n",
        "    print(f\"--- Callback: Allowing tool '{tool_name}' to proceed. ---\")\n",
        "    return None # Returning None allows the actual tool function to run\n",
        "\n",
        "print(\"✅ block_paris_tool_guardrail function defined.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d01OYJlauSI"
      },
      "source": [
        "---\n",
        "\n",
        "**2\\. Update Root Agent to Use Both Callbacks**\n",
        "\n",
        "We redefine the root agent again (`weather_agent_v6_tool_guardrail`), this time adding the `before_tool_callback` parameter alongside the `before_model_callback` from Step 5\\.\n",
        "\n",
        "*Self-Contained Execution Note:* Similar to Step 5, ensure all prerequisites (sub-agents, tools, `before_model_callback`) are defined or available in the execution context before defining this agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BVIl_3uLTZT"
      },
      "outputs": [],
      "source": [
        "# @title 2. Update Root Agent with BOTH Callbacks (Self-Contained)\n",
        "\n",
        "# --- Ensure Prerequisites are Defined ---\n",
        "# (Include or ensure execution of definitions for: Agent, LiteLlm, Runner, ToolContext,\n",
        "#  MODEL constants, say_hello, say_goodbye, greeting_agent, farewell_agent,\n",
        "#  get_weather_stateful, block_keyword_guardrail, block_paris_tool_guardrail)\n",
        "\n",
        "# --- Redefine Sub-Agents (Ensures they exist in this context) ---\n",
        "greeting_agent = None\n",
        "try:\n",
        "    # Use a defined model constant like MODEL_GPT_o3_MINI\n",
        "    greeting_agent = Agent(\n",
        "        model=MODEL_GEMINI_2_0_FLASH,\n",
        "        name=\"greeting_agent\", # Keep original name for consistency\n",
        "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n",
        "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n",
        "        tools=[say_hello],\n",
        "    )\n",
        "    print(f\"✅ Sub-Agent '{greeting_agent.name}' redefined.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not redefine Greeting agent. Check Model/API Key ({MODEL_GPT_o3_MINI}). Error: {e}\")\n",
        "\n",
        "farewell_agent = None\n",
        "try:\n",
        "    # Use a defined model constant like MODEL_GPT_o3_MINI\n",
        "    farewell_agent = Agent(\n",
        "        model=LiteLlm(model=MODEL_GPT_o3_MINI),\n",
        "        name=\"farewell_agent\", # Keep original name\n",
        "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n",
        "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n",
        "        tools=[say_goodbye],\n",
        "    )\n",
        "    print(f\"✅ Sub-Agent '{farewell_agent.name}' redefined.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not redefine Farewell agent. Check Model/API Key ({MODEL_GPT_o3_MINI}). Error: {e}\")\n",
        "\n",
        "# --- Define the Root Agent with Both Callbacks ---\n",
        "root_agent_tool_guardrail = None\n",
        "runner_root_tool_guardrail = None\n",
        "\n",
        "if ('greeting_agent' in globals() and greeting_agent and\n",
        "    'farewell_agent' in globals() and farewell_agent and\n",
        "    'get_weather_stateful' in globals() and\n",
        "    'block_keyword_guardrail' in globals() and\n",
        "    'block_paris_tool_guardrail' in globals()):\n",
        "\n",
        "    root_agent_model = MODEL_GEMINI_2_0_FLASH\n",
        "\n",
        "    root_agent_tool_guardrail = Agent(\n",
        "        name=\"weather_agent_v6_tool_guardrail\", # New version name\n",
        "        model=root_agent_model,\n",
        "        description=\"Main agent: Handles weather, delegates, includes input AND tool guardrails.\",\n",
        "        instruction=\"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \"\n",
        "                    \"Delegate greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n",
        "                    \"Handle only weather, greetings, and farewells.\",\n",
        "        tools=[get_weather_stateful],\n",
        "        sub_agents=[greeting_agent, farewell_agent],\n",
        "        output_key=\"last_weather_report\",\n",
        "        before_model_callback=block_keyword_guardrail, # Keep model guardrail\n",
        "        before_tool_callback=block_paris_tool_guardrail # <<< Add tool guardrail\n",
        "    )\n",
        "    print(f\"✅ Root Agent '{root_agent_tool_guardrail.name}' created with BOTH callbacks.\")\n",
        "\n",
        "    # --- Create Runner, Using SAME Stateful Session Service ---\n",
        "    if 'session_service_stateful' in globals():\n",
        "        runner_root_tool_guardrail = Runner(\n",
        "            agent=root_agent_tool_guardrail,\n",
        "            app_name=APP_NAME,\n",
        "            session_service=session_service_stateful # <<< Use the service from Step 4/5\n",
        "        )\n",
        "        print(f\"✅ Runner created for tool guardrail agent '{runner_root_tool_guardrail.agent.name}', using stateful session service.\")\n",
        "    else:\n",
        "        print(\"❌ Cannot create runner. 'session_service_stateful' from Step 4/5 is missing.\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Cannot create root agent with tool guardrail. Prerequisites missing.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUo-nu657kc8"
      },
      "source": [
        "---\n",
        "\n",
        "**3\\. Interact to Test the Tool Guardrail**\n",
        "\n",
        "Let's test the interaction flow, again using the same stateful session (`SESSION_ID_STATEFUL`) from the previous steps.\n",
        "\n",
        "1. Request weather for \"New York\": Passes both callbacks, tool executes (using Fahrenheit preference from state).  \n",
        "2. Request weather for \"Paris\": Passes `before_model_callback`. LLM decides to call `get_weather_stateful(city='Paris')`. `before_tool_callback` intercepts, blocks the tool, and returns the error dictionary. Agent relays this error.  \n",
        "3. Request weather for \"London\": Passes both callbacks, tool executes normally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpg4fzkLav1-"
      },
      "outputs": [],
      "source": [
        "# @title 3. Interact to Test the Tool Argument Guardrail\n",
        "\n",
        "# Ensure the runner for the tool guardrail agent is available\n",
        "if runner_root_tool_guardrail:\n",
        "  async def run_tool_guardrail_test():\n",
        "      print(\"\\n--- Testing Tool Argument Guardrail ('Paris' blocked) ---\")\n",
        "\n",
        "        # Use the runner for the agent with both callbacks and the existing stateful session\n",
        "      interaction_func = lambda query: call_agent_async(query,\n",
        "      runner_root_tool_guardrail, USER_ID_STATEFUL, SESSION_ID_STATEFUL\n",
        "  )\n",
        "      # 1. Allowed city (Should pass both callbacks, use Fahrenheit state)\n",
        "      await interaction_func(\"What's the weather in New York?\")\n",
        "\n",
        "      # 2. Blocked city (Should pass model callback, but be blocked by tool callback)\n",
        "      await interaction_func(\"How about Paris?\")\n",
        "\n",
        "      # 3. Another allowed city (Should work normally again)\n",
        "      await interaction_func(\"Tell me the weather in London.\")\n",
        "\n",
        "  # Execute the conversation\n",
        "  await run_tool_guardrail_test()\n",
        "\n",
        "  # Optional: Check state for the tool block trigger flag\n",
        "  final_session = session_service_stateful.get_session(app_name=APP_NAME,\n",
        "                                                       user_id=USER_ID_STATEFUL,\n",
        "                                                       session_id= SESSION_ID_STATEFUL)\n",
        "  if final_session:\n",
        "      print(\"\\n--- Final Session State (After Tool Guardrail Test) ---\")\n",
        "      print(f\"Tool Guardrail Triggered Flag: {final_session.state.get('guardrail_tool_block_triggered')}\")\n",
        "      print(f\"Last Weather Report: {final_session.state.get('last_weather_report')}\") # Should be London weather\n",
        "      print(f\"Temperature Unit: {final_session.state.get('user_preference_temperature_unit')}\") # Should be Fahrenheit\n",
        "  else:\n",
        "      print(\"\\n❌ Error: Could not retrieve final session state.\")\n",
        "\n",
        "else:\n",
        "  print(\"\\n⚠️ Skipping tool guardrail test. Runner ('runner_root_tool_guardrail') is not available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gCcBgMfa1VS"
      },
      "source": [
        "---\n",
        "\n",
        "Analyze the output:\n",
        "\n",
        "1. **New York:** The `before_model_callback` allows the request. The LLM requests `get_weather_stateful`. The `before_tool_callback` runs, inspects the args (`{'city': 'New York'}`), sees it's not \"Paris\", prints \"Allowing tool...\" and returns `None`. The actual `get_weather_stateful` function executes, reads \"Fahrenheit\" from state, and returns the weather report. The agent relays this, and it gets saved via `output_key`.  \n",
        "2. **Paris:** The `before_model_callback` allows the request. The LLM requests `get_weather_stateful(city='Paris')`. The `before_tool_callback` runs, inspects the args, detects \"Paris\", prints \"Blocking tool execution\\!\", sets the state flag, and returns the error dictionary `{'status': 'error', 'error_message': 'Policy restriction...'}`. The actual `get_weather_stateful` function is **never executed**. The agent receives the error dictionary *as if it were the tool's output* and formulates a response based on that error message.  \n",
        "3. **London:** Behaves like New York, passing both callbacks and executing the tool successfully. The new London weather report overwrites the `last_weather_report` in the state.\n",
        "\n",
        "You've now added a crucial safety layer controlling not just *what* reaches the LLM, but also *how* the agent's tools can be used based on the specific arguments generated by the LLM. Callbacks like `before_model_callback` and `before_tool_callback` are essential for building robust, safe, and policy-compliant agent applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYWtGbdI8DZw"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Conclusion: Your Agent Team is Ready!\n",
        "\n",
        "Congratulations! You've successfully journeyed from building a single, basic weather agent to constructing a sophisticated, multi-agent team using the Agent Development Kit (ADK).\n",
        "\n",
        "**Let's recap what you've accomplished:**\n",
        "\n",
        "*   You started with a **fundamental agent** equipped with a single tool (`get_weather`).\n",
        "*   You explored ADK's **multi-model flexibility** using LiteLLM, running the same core logic with different LLMs like Gemini, GPT-4o, and Claude.\n",
        "*   You embraced **modularity** by creating specialized sub-agents (`greeting_agent`, `farewell_agent`) and enabling **automatic delegation** from a root agent.\n",
        "*   You gave your agents **memory** using **Session State**, allowing them to remember user preferences (`temperature_unit`) and past interactions (`output_key`).\n",
        "*   You implemented crucial **safety guardrails** using both `before_model_callback` (blocking specific input keywords) and `before_tool_callback` (blocking tool execution based on arguments like the city \"Paris\").\n",
        "\n",
        "Through building this progressive Weather Bot team, you've gained hands-on experience with core ADK concepts essential for developing complex, intelligent applications.\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "*   **Agents & Tools:** The fundamental building blocks for defining capabilities and reasoning. Clear instructions and docstrings are paramount.\n",
        "*   **Runners & Session Services:** The engine and memory management system that orchestrate agent execution and maintain conversational context.\n",
        "*   **Delegation:** Designing multi-agent teams allows for specialization, modularity, and better management of complex tasks. Agent `description` is key for auto-flow.\n",
        "*   **Session State (`ToolContext`, `output_key`):** Essential for creating context-aware, personalized, and multi-turn conversational agents.\n",
        "*   **Callbacks (`before_model`, `before_tool`):** Powerful hooks for implementing safety, validation, policy enforcement, and dynamic modifications *before* critical operations (LLM calls or tool execution).\n",
        "*   **Flexibility (`LiteLlm`):** ADK empowers you to choose the best LLM for the job, balancing performance, cost, and features.\n",
        "\n",
        "**Where to Go Next?**\n",
        "\n",
        "Your Weather Bot team is a great starting point. Here are some ideas to further explore ADK and enhance your application:\n",
        "\n",
        "1.  **Real Weather API:** Replace the `mock_weather_db` in your `get_weather` tool with a call to a real weather API (like OpenWeatherMap, WeatherAPI).\n",
        "2.  **More Complex State:** Store more user preferences (e.g., preferred location, notification settings) or conversation summaries in the session state.\n",
        "3.  **Refine Delegation:** Experiment with different root agent instructions or sub-agent descriptions to fine-tune the delegation logic. Could you add a \"forecast\" agent?\n",
        "4.  **Advanced Callbacks:**\n",
        "    *   Use `after_model_callback` to potentially reformat or sanitize the LLM's response *after* it's generated.\n",
        "    *   Use `after_tool_callback` to process or log the results returned by a tool.\n",
        "    *   Implement `before_agent_callback` or `after_agent_callback` for agent-level entry/exit logic.\n",
        "5.  **Error Handling:** Improve how the agent handles tool errors or unexpected API responses. Maybe add retry logic within a tool.\n",
        "6.  **Persistent Session Storage:** Explore alternatives to `InMemorySessionService` for storing session state persistently (e.g., using databases like Firestore or Cloud SQL – requires custom implementation or future ADK integrations).\n",
        "7.  **Streaming UI:** Integrate your agent team with a web framework (like FastAPI, as shown in the ADK Streaming Quickstart) to create a real-time chat interface.\n",
        "\n",
        "The Agent Development Kit provides a robust foundation for building sophisticated LLM-powered applications. By mastering the concepts covered in this tutorial – tools, state, delegation, and callbacks – you are well-equipped to tackle increasingly complex agentic systems.\n",
        "\n",
        "Happy building!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "python3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
